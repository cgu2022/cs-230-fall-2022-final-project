{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72bf15ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "# import audiomentations\n",
    "# from audiomentations import Compose, AddGaussianNoise, PitchShift\n",
    "# import torch_audiomentations\n",
    "# from torch_audiomentations import Compose, AddGaussianNoise, PitchShift\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f88ba65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# total = len(train_df)\n",
    "# healthy = 1-(counts[\"healthy\"]/total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6fe837a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from https://github.com/musikalkemist/pytorchforaudio\n",
    "class CoughDataset(Dataset):\n",
    "\n",
    "    def __init__(self,\n",
    "                 annotations_df,\n",
    "                 audio_dir,\n",
    "                 transformation,\n",
    "                 target_sample_rate,\n",
    "                 num_samples,\n",
    "                 device,\n",
    "                 augment=False,\n",
    "                ):\n",
    "        self.annotations = annotations_df\n",
    "        self.audio_dir = audio_dir\n",
    "        self.device = device\n",
    "        self.transformation = transformation.to(self.device)\n",
    "        self.target_sample_rate = target_sample_rate\n",
    "        self.num_samples = num_samples\n",
    "        self.label_dict = {'healthy':0, 'symptomatic':1, 'COVID-19':2}\n",
    "        self.label_weights = self._calculate_weights(annotations_df)\n",
    "        \n",
    "        self.do_augment = augment\n",
    "#         self.augmentations = Compose(\n",
    "#                 [\n",
    "#                     AddGaussianNoise(min_amplitude=0.01, max_amplitude=0.05, p=0.5),\n",
    "#                     PitchShift(min_semitones=-8, max_semitones=8, p=0.5)\n",
    "#                 ]\n",
    "#         )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        audio_sample_path = self._get_audio_sample_path(index)\n",
    "        label = self.label_dict[self._get_audio_sample_label(index)]\n",
    "        signal, sr = torchaudio.load(audio_sample_path)        \n",
    "        signal = signal.to(self.device)\n",
    "        signal = self._resample_if_necessary(signal, sr)\n",
    "        signal = self._mix_down_if_necessary(signal)\n",
    "        signal = self._cut_if_necessary(signal)\n",
    "        signal = self._right_pad_if_necessary(signal)\n",
    "        signal = self.transformation(signal)\n",
    "\n",
    "        return signal, label\n",
    "\n",
    "    def _calculate_weights(self, annotation_df):\n",
    "        counts = annotation_df[\"status\"].value_counts()\n",
    "        total = len(annotation_df)\n",
    "        weights = (1-(counts/total))\n",
    "        weights /= weights.sum()\n",
    "        return torch.FloatTensor(weights)\n",
    "\n",
    "    def _cut_if_necessary(self, signal):\n",
    "        if signal.shape[1] > self.num_samples:\n",
    "            signal = signal[:, :self.num_samples]\n",
    "        return signal\n",
    "\n",
    "    def _right_pad_if_necessary(self, signal):\n",
    "        length_signal = signal.shape[1]\n",
    "        if length_signal < self.num_samples:\n",
    "            num_missing_samples = self.num_samples - length_signal\n",
    "            last_dim_padding = (0, num_missing_samples)\n",
    "            signal = torch.nn.functional.pad(signal, last_dim_padding)\n",
    "        return signal\n",
    "\n",
    "    def _resample_if_necessary(self, signal, sr):\n",
    "        if sr != self.target_sample_rate:\n",
    "            resampler = torchaudio.transforms.Resample(sr, self.target_sample_rate)\n",
    "            signal = resampler(signal)\n",
    "        return signal\n",
    "\n",
    "    def _mix_down_if_necessary(self, signal):\n",
    "        if signal.shape[0] > 1:\n",
    "            signal = torch.mean(signal, dim=0, keepdim=True)\n",
    "        return signal\n",
    "\n",
    "    def _get_audio_sample_path(self, index):\n",
    "        path = os.path.join(self.audio_dir, self.annotations.iloc[index, 0])+\".wav\"\n",
    "        return path\n",
    "\n",
    "    def _get_audio_sample_label(self, index):\n",
    "        return self.annotations.iloc[index, 9]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5a17a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_DIR = \"../valid_data/\"\n",
    "SAMPLE_RATE = 16000\n",
    "NUM_SAMPLES = SAMPLE_RATE*10\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "# print(f\"Using device {device}\")\n",
    "\n",
    "# train_df = pd.read_parquet(os.path.join(AUDIO_DIR, \"train.parquet.gzip\"))\n",
    "# val_df = pd.read_parquet(os.path.join(AUDIO_DIR, \"val.parquet.gzip\"))\n",
    "# test_df = pd.read_parquet(os.path.join(AUDIO_DIR, \"test.parquet.gzip\"))\n",
    "\n",
    "train_df = pd.read_parquet(os.path.join(AUDIO_DIR, \"train_edited.parquet.gzip\"))\n",
    "val_df = pd.read_parquet(os.path.join(AUDIO_DIR, \"val_edited.parquet.gzip\"))\n",
    "test_df = pd.read_parquet(os.path.join(AUDIO_DIR, \"test_edited.parquet.gzip\"))\n",
    "\n",
    "# print(f\"There are {len(usd)} samples in the dataset.\")\n",
    "# signal, label = usd[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c258e123",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNNetwork(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, drop_p=0.2):\n",
    "        super().__init__()\n",
    "        # 4 conv blocks / flatten / linear / softmax\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=16,\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "                padding=0\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.Dropout(p=drop_p)\n",
    "\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=16,\n",
    "                out_channels=32,\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "                padding=0\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Dropout(p=drop_p)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=32,\n",
    "                out_channels=64,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=0\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Dropout(p=drop_p)\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=64,\n",
    "                out_channels=128,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=0\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Dropout(p=drop_p)\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear = nn.Linear(31744, 3)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        #nomralization\n",
    "        std = input_data.std()\n",
    "        input_data -= input_data.mean()\n",
    "        input_data /= std\n",
    "        \n",
    "        x = self.conv1(input_data)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear(x)\n",
    "        predictions = self.softmax(logits)\n",
    "        return predictions\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c406986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loader(train_data, batch_size):\n",
    "    train_dataloader = DataLoader(train_data, batch_size=batch_size)\n",
    "    return train_dataloader\n",
    "\n",
    "def count_correct(logits, y_true):\n",
    "    y_pred = torch.argmax(logits, axis = 1)\n",
    "    return torch.sum(y_pred==y_true)\n",
    "\n",
    "def train_single_epoch(model, train_data_loader, val_data_loader, loss_fn, optimiser, device):\n",
    "    total_loss = 0.0\n",
    "    correct_pred = 0.0\n",
    "    total_pred = 0\n",
    "    for x_batch, y_batch in tqdm(train_data_loader):\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        # calculate loss\n",
    "        y_pred = model(x_batch)\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        \n",
    "        correct_pred += count_correct(y_pred, y_batch)\n",
    "        total_pred += y_batch.shape[0]\n",
    "\n",
    "        # backpropagate error and update weights\n",
    "        optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f\"Training loss: {total_loss}, Training accuracy : {correct_pred/total_pred}\")\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    correct_pred = 0.0\n",
    "    total_pred = 0\n",
    "    for x_batch, y_batch in tqdm(val_data_loader):\n",
    "        with torch.no_grad():\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            y_pred = model(x_batch)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            total_loss += loss.item() \n",
    "            \n",
    "        correct_pred += count_correct(y_pred, y_batch)\n",
    "        total_pred += y_batch.shape[0]\n",
    "        \n",
    "    print(f\"Validataion loss: {total_loss}, Validation accuracy : {correct_pred/total_pred}\")\n",
    "\n",
    "    \n",
    "def train(model, train_data_loader, val_data_loader, loss_fn, optimiser, device, epochs):\n",
    "    for i in range(epochs):\n",
    "        print(f\"Epoch {i+1}\")\n",
    "        train_single_epoch(model, train_data_loader, val_data_loader, loss_fn, optimiser, device)\n",
    "        \n",
    "        path = os.path.join(MODEL_FOLDER, f\"epoch_{i}.pth\")\n",
    "        torch.save(model.state_dict(), path)\n",
    "        print(f\"Saved at {path}\")\n",
    "        print(\"---------------------------\")\n",
    "    print(\"Finished training\")\n",
    "    print(\"---------------------------\")\n",
    "    \n",
    "    \n",
    "def evaluate(model, eval_data_loader, loss_fn, device):\n",
    "    print(\"Evaluating model\")\n",
    "    total_loss = 0.0\n",
    "    correct_pred = 0.0\n",
    "    total_pred = 0\n",
    "    for x_batch, y_batch in tqdm(eval_data_loader):\n",
    "        with torch.no_grad():\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            # calculate loss\n",
    "            y_pred = model(x_batch)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "\n",
    "            correct_pred += count_correct(y_pred, y_batch)\n",
    "            total_pred += y_batch.shape[0]\n",
    "\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "    print(f\"Evaluation loss: {total_loss}, Evaluation accuracy : {correct_pred/total_pred}\")\n",
    "    print(\"---------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b393f0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE =16\n",
    "EPOCHS = 10\n",
    "MODEL_FOLDER = \"../models/\"\n",
    "\n",
    "mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n",
    "    sample_rate=SAMPLE_RATE,\n",
    "    n_fft=1024,\n",
    "    hop_length=512,\n",
    "    n_mels=128\n",
    ")\n",
    "\n",
    "train_data = CoughDataset(train_df,\n",
    "                        AUDIO_DIR,\n",
    "                        mel_spectrogram,\n",
    "                        SAMPLE_RATE,\n",
    "                        NUM_SAMPLES,\n",
    "                        device)\n",
    "\n",
    "val_data = CoughDataset(val_df,\n",
    "                        AUDIO_DIR,\n",
    "                        mel_spectrogram,\n",
    "                        SAMPLE_RATE,\n",
    "                        NUM_SAMPLES,\n",
    "                        device)\n",
    "\n",
    "test_data = CoughDataset(test_df,\n",
    "                        AUDIO_DIR,\n",
    "                        mel_spectrogram,\n",
    "                        SAMPLE_RATE,\n",
    "                        NUM_SAMPLES,\n",
    "                        device)\n",
    "\n",
    "train_dataloader = create_data_loader(train_data, BATCH_SIZE)\n",
    "val_dataloader = create_data_loader(val_data, BATCH_SIZE)\n",
    "test_dataloader = create_data_loader(val_data, BATCH_SIZE)\n",
    "\n",
    "# construct model and assign it to device\n",
    "model = CNNNetwork().to(device)\n",
    "\n",
    "# initialise loss funtion + optimiser\n",
    "loss_fn = nn.CrossEntropyLoss(weight=train_data.label_weights)\n",
    "optimiser = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373d65a0",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------------------------------Serena: Data Processing\n",
    "\n",
    "Get all the bad wav files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1f19114",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13535/13535 [00:31<00:00, 434.77it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# train_df = pd.read_parquet(os.path.join(AUDIO_DIR, \"train.parquet.gzip\"))\n",
    "# all_df = pd.read_parquet(os.path.join(AUDIO_DIR, \"metadata_compiled_valid.parquet.gzip\"))\n",
    "# # loop through all samples and load\n",
    "# error_files = []\n",
    "# error_labels = []\n",
    "# for i in tqdm(range(len(all_df))):\n",
    "#     path = os.path.join(AUDIO_DIR, all_df.iloc[i, 0])+\".wav\"\n",
    "#     label = all_df.iloc[i, 9]\n",
    "#     try:\n",
    "#         audio, sr = torchaudio.load(path)\n",
    "#     except:\n",
    "#         #print(f\"Error loading {path}\")\n",
    "#         error_files.append(path)\n",
    "#         error_labels.append(label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e26e47",
   "metadata": {},
   "source": [
    "Count how many bad wav files there are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c4b97384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Number of bad wav files in all:', len(error_files))\n",
    "# #count how many of each label\n",
    "# healthy = 0\n",
    "# covid = 0\n",
    "# symptomatic = 0\n",
    "# for label in error_labels:\n",
    "#     if label == 'healthy':\n",
    "#         healthy += 1\n",
    "#     elif label == 'COVID-19':\n",
    "#         covid += 1\n",
    "#     elif label == 'symptomatic':\n",
    "#         symptomatic += 1\n",
    "# print('Number of bad healthy samples:', healthy)\n",
    "# print('Number of bad covid samples:', covid)\n",
    "# print('Number of bad symptomatic samples:', symptomatic)\n",
    "\n",
    "\n",
    "# #write error_files to csv\n",
    "# with open('error_files.csv', 'w') as f:\n",
    "#     for item in error_files:\n",
    "#         f.write(item[14:-4])\n",
    "#         f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c29e91",
   "metadata": {},
   "source": [
    "Try reconverting all the bad wav files -- found that they are all existing wav files in the folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1311c9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import subprocess\n",
    "\n",
    "\n",
    "# coughvid = '../../coughvid_20211012/'\n",
    "# current_dir = os.getcwd()\n",
    "\n",
    "# #read in error files in pd\n",
    "# error_files = pd.read_csv('error_files.csv', header=None)\n",
    "# #cut off the front and .wav at the end\n",
    "# test = error_files[0].str[14:-4]\n",
    "\n",
    "# count = 0\n",
    "# for file in tqdm(test):\n",
    "# # run ffmpeg -i \"file.webm\" -vn \"file.wav\" in terminal to convert to wav\n",
    "#     print(coughvid + file + '.webm')\n",
    "#     if os.path.isfile(coughvid + file + '.webm'):\n",
    "#         subprocess.call([\"ffmpeg\", \"-i\", coughvid+file+\".webm\", current_dir+'./temp_wav/'+file+\".wav\"])\n",
    "#     elif os.path.isfile(coughvid + file + '.ogg'):\n",
    "#         subprocess.call([\"ffmpeg\", \"-i\", coughvid+file+\".ogg\", current_dir+'./temp_wav/'+file+\".wav\"])\n",
    "#     else:\n",
    "#         print(\"Error: No file name {0}\".format(file))\n",
    "#         count += 1\n",
    "# print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041a8d59",
   "metadata": {},
   "source": [
    "Create the new data without the bad wav files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56606d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 788/788 [00:06<00:00, 130.51it/s]\n"
     ]
    }
   ],
   "source": [
    "# all_df = pd.read_parquet(os.path.join(AUDIO_DIR, \"metadata_compiled_valid.parquet.gzip\"))\n",
    "# # for each file name in error files\n",
    "# # remove it from all_df\n",
    "# # create new train/test split\n",
    "\n",
    "\n",
    "# #read in error files in pd\n",
    "# error_files = pd.read_csv('error_files.csv', header=None)\n",
    "\n",
    "# #for each file name in error files\n",
    "# #remove it from all_df\n",
    "# # create new train/test split\n",
    "# for file in tqdm(error_files[0]):\n",
    "#     #if file equals uuid in all_df remove it from all_df\n",
    "#     #remove row from all_df\n",
    "#     all_df = all_df.drop(all_df.index[all_df['uuid'] == file])\n",
    "\n",
    "# #save new all_df\n",
    "# all_df.to_parquet(os.path.join(AUDIO_DIR, \"metadata_compiled_valid_edited.parquet.gzip\"))\n",
    "# #save new all_df as csv\n",
    "# all_df.to_csv(os.path.join(AUDIO_DIR, \"metadata_compiled_valid_edited.csv\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0659416f",
   "metadata": {},
   "source": [
    "Serena: Data Processing End\n",
    "---------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "849e78e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 646/646 [06:05<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 701.4169194698334, Training accuracy : 0.6145873665809631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:24<00:00,  2.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validataion loss: 77.30932474136353, Validation accuracy : 0.6794425249099731\n",
      "Saved at ../models/epoch_0.pth\n",
      "---------------------------\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 646/646 [07:11<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 709.7027128338814, Training accuracy : 0.5757458209991455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:24<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validataion loss: 83.49944651126862, Validation accuracy : 0.3519163727760315\n",
      "Saved at ../models/epoch_1.pth\n",
      "---------------------------\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 646/646 [06:21<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 737.6401586532593, Training accuracy : 0.38870593905448914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:23<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validataion loss: 78.79910546541214, Validation accuracy : 0.5121951103210449\n",
      "Saved at ../models/epoch_2.pth\n",
      "---------------------------\n",
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 646/646 [06:43<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 709.5324600934982, Training accuracy : 0.5627663731575012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:33<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validataion loss: 77.62892323732376, Validation accuracy : 0.5862369537353516\n",
      "Saved at ../models/epoch_3.pth\n",
      "---------------------------\n",
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 646/646 [07:54<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 686.0553515553474, Training accuracy : 0.6718326210975647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:22<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validataion loss: 77.50787502527237, Validation accuracy : 0.6811846494674683\n",
      "Saved at ../models/epoch_4.pth\n",
      "---------------------------\n",
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 646/646 [06:07<00:00,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 687.6860538721085, Training accuracy : 0.6762882471084595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:24<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validataion loss: 77.12485110759735, Validation accuracy : 0.661149799823761\n",
      "Saved at ../models/epoch_5.pth\n",
      "---------------------------\n",
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 646/646 [05:41<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 684.5094707608223, Training accuracy : 0.7089306712150574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:23<00:00,  3.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validataion loss: 76.40202713012695, Validation accuracy : 0.7439024448394775\n",
      "Saved at ../models/epoch_6.pth\n",
      "---------------------------\n",
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 646/646 [05:43<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 679.521864593029, Training accuracy : 0.7492250800132751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:23<00:00,  3.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validataion loss: 76.30245167016983, Validation accuracy : 0.7473867535591125\n",
      "Saved at ../models/epoch_7.pth\n",
      "---------------------------\n",
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 646/646 [05:41<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 678.7914835810661, Training accuracy : 0.7282060980796814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:23<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validataion loss: 76.0000592470169, Validation accuracy : 0.7386759519577026\n",
      "Saved at ../models/epoch_8.pth\n",
      "---------------------------\n",
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 646/646 [06:12<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 679.8163275122643, Training accuracy : 0.7475784420967102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:35<00:00,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validataion loss: 76.16243559122086, Validation accuracy : 0.7526132464408875\n",
      "Saved at ../models/epoch_9.pth\n",
      "---------------------------\n",
      "Finished training\n",
      "---------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(model, train_dataloader, val_dataloader, loss_fn, optimiser, device, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0be4c890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:32<00:00,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation loss: 76.06606262922287, Evaluation accuracy : 0.7543553709983826\n",
      "---------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(model, test_dataloader, loss_fn, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4270da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92ad25a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "def evaluate_confusion(model, eval_data_loader, device):\n",
    "    trues = []\n",
    "    preds =[]\n",
    "    for x_batch, y_batch in tqdm(eval_data_loader):\n",
    "        with torch.no_grad():\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            # calculate loss\n",
    "            y_pred = model(x_batch)\n",
    "\n",
    "\n",
    "            trues += torch.clamp(y_batch, max=1)\n",
    "\n",
    "\n",
    "            preds += torch.clamp(torch.argmax(y_pred, axis = 1), max=1)\n",
    "            \n",
    "            \n",
    "    return np.array(trues), np.array(preds)\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "494fdd01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:30<00:00,  2.40it/s]\n"
     ]
    }
   ],
   "source": [
    "trues, preds = evaluate_confusion(model, test_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2eba3ddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x156fd0b20>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjUAAAGwCAYAAABRgJRuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAABOfElEQVR4nO3deVxU9f7H8deAsggMiAmIImqu5K6lU5laJKmZpi2WKe43Q0u9mnXLJc0sW/Rapm1u92ZdM/UWlkmUWkmalt1SNDV3RSpExGKbOb8/vMyvuWgxDIhzfD8fj/OoOef7PeczPig+fr7LsRiGYSAiIiLi5XwqOwARERGR8qCkRkRERExBSY2IiIiYgpIaERERMQUlNSIiImIKSmpERETEFJTUiIiIiClUqewApHQcDgfHjx8nJCQEi8VS2eGIiIgbDMPgzJkzREdH4+NTcfWEvLw8CgoKPL6Pn58fAQEB5RDRxaWkxkscP36cmJiYyg5DREQ8cOTIEerUqVMh987Ly6N+bDAZmXaP7xUVFcWBAwe8LrFRUuMlQkJCADj0dT2swRo1FHO6vUnLyg5BpEIUGYV8zlrn/8srQkFBARmZdg5tr4c1pOy/J3LOOIhtd5CCggIlNVIxioecrME+Hv2wilzKqliqVnYIIhXH4KJMHwgOsRAcUvbnOPDeKQ5KakREREzEbjiwe/BWR7vhKL9gLjIlNSIiIibiwMBB2bMaT/pWNo1jiIiIiCmoUiMiImIiDhx4MoDkWe/KpaRGRETEROyGgd0o+xCSJ30rm4afRERExBRUqRERETGRy3misJIaERERE3FgYL9MkxoNP4mIiIgpqFIjIiJiIhp+EhEREVPQ6icRERERL6dKjYiIiIk4/nt40t9bKakRERExEbuHq5886VvZlNSIiIiYiN3Aw7d0l18sF5vm1IiIiIgpqFIjIiJiIppTIyIiIqbgwIIdi0f9vZWGn0RERMQUVKkRERExEYdx7vCkv7dSUiMiImIidg+HnzzpW9k0/CQiIiJlZrfbmTx5MvXr1ycwMJArr7ySGTNmYPzudQuGYTBlyhRq1apFYGAg8fHx7N271+U+WVlZDBgwAKvVSlhYGMOGDSM3N9etWJTUiIiImEhxpcaTwx3PPPMMCxYs4KWXXiI9PZ1nnnmG2bNn8+KLLzrbzJ49m3nz5rFw4UK2bNlCUFAQCQkJ5OXlOdsMGDCAnTt3kpKSQnJyMps2bWLkyJFuxaLhJxERERNxGBYchgern9zsu3nzZnr37k3Pnj0BqFevHm+99RZbt24FzlVp5s6dy+OPP07v3r0BWLZsGZGRkaxZs4b+/fuTnp7OunXr+Oqrr2jfvj0AL774Ij169OC5554jOjq6VLGoUiMiIiIl5OTkuBz5+fnnbXfttdeSmprKDz/8AMC3337L559/Tvfu3QE4cOAAGRkZxMfHO/uEhobSoUMH0tLSAEhLSyMsLMyZ0ADEx8fj4+PDli1bSh2zKjUiIiImUl4ThWNiYlzOT506lWnTppVo/8gjj5CTk0PTpk3x9fXFbrczc+ZMBgwYAEBGRgYAkZGRLv0iIyOd1zIyMoiIiHC5XqVKFcLDw51tSkNJjYiIiInY8cHuwUCM/b//PHLkCFar1Xne39//vO1XrFjBm2++yfLly7nqqqvYsWMHY8eOJTo6msTExDLHURZKakREREzE8HBOjfHfvlar1SWpuZCJEyfyyCOP0L9/fwBatGjBoUOHmDVrFomJiURFRQFw8uRJatWq5ex38uRJWrduDUBUVBSZmZku9y0qKiIrK8vZvzQ0p0ZERETK7Ndff8XHxzWd8PX1xeE49xap+vXrExUVRWpqqvN6Tk4OW7ZswWazAWCz2cjOzmb79u3ONp988gkOh4MOHTqUOhZVakREREzkYm++16tXL2bOnEndunW56qqr+Oabb3jhhRcYOnQoABaLhbFjx/Lkk0/SqFEj6tevz+TJk4mOjqZPnz4ANGvWjFtuuYURI0awcOFCCgsLGT16NP379y/1yidQUiMiImIqdsMHu+HBnBo3X5Pw4osvMnnyZB544AEyMzOJjo7mL3/5C1OmTHG2efjhhzl79iwjR44kOzub66+/nnXr1hEQEOBs8+abbzJ69GhuuukmfHx86NevH/PmzXMrFovx+y3/5JKVk5NDaGgop35ogDVEo4ZiTgm121R2CCIVosgoZIOxhtOnT5dqnkpZFP+e+PA/9Qny4PfE2TMOurc8UKGxVhRVakREREzEgQWHB1NmHXhvrUNJjYiIiInohZYiIiIiXk6VGhERERPxfKKwhp9ERETkEnBuTo0HL7TU8JOIiIhI5VKlRkRExEQcHr77SaufRERE5JKgOTUiIiJiCg58Ltt9ajSnRkRERExBlRoRERETsRsW7IYHm+950LeyKakRERExEbuHE4XtGn4SERERqVyq1IiIiJiIw/DB4cHqJ4dWP4mIiMilQMNPIiIiIl5OlRoRERETceDZCiZH+YVy0SmpERERMRHPN9/z3kEc741cRERE5HdUqRERETERz9/95L31DiU1IiIiJuLAggNP5tRoR2ERERG5BFzOlRrvjVxERETkd1SpERERMRHPN9/z3nqHkhoRERETcRgWHJ7sU+PFb+n23nRMRERE5HdUqRERETERh4fDT968+Z6SGhERERPx/C3d3pvUeG/kIiIiIr+jSo2IiIiJ2LFg92ADPU/6VjYlNSIiIiai4ScRERERL6ekRkRExETs/P8QVNkO99SrVw+LxVLiSEpKAiAvL4+kpCRq1KhBcHAw/fr14+TJky73OHz4MD179qRatWpEREQwceJEioqK3P7uGn4SERExkYs9/PTVV19ht/9/KvT9999z8803c+eddwIwbtw41q5dyzvvvENoaCijR4+mb9++fPHFFwDY7XZ69uxJVFQUmzdv5sSJEwwaNIiqVavy1FNPuRWLkhoRERETudgvtKxZs6bL56effporr7ySzp07c/r0ad544w2WL1/OjTfeCMDixYtp1qwZX375JR07dmT9+vXs2rWLjz/+mMjISFq3bs2MGTOYNGkS06ZNw8/Pr9SxaPhJRERESsjJyXE58vPz/7RPQUEB//znPxk6dCgWi4Xt27dTWFhIfHy8s03Tpk2pW7cuaWlpAKSlpdGiRQsiIyOdbRISEsjJyWHnzp1uxaykRkRExEQMLDg8OIz/LumOiYkhNDTUecyaNetPn71mzRqys7MZPHgwABkZGfj5+REWFubSLjIykoyMDGeb3yc0xdeLr7lDw08iIiImUl7DT0eOHMFqtTrP+/v7/2nfN954g+7duxMdHV3m53tCSY2IiIiUYLVaXZKaP3Po0CE+/vhjVq1a5TwXFRVFQUEB2dnZLtWakydPEhUV5WyzdetWl3sVr44qblNaGn4SERExEYdh8fgoi8WLFxMREUHPnj2d59q1a0fVqlVJTU11ntuzZw+HDx/GZrMBYLPZ+O6778jMzHS2SUlJwWq1EhcX51YMqtSIiIiYiN3Dt3SXpa/D4WDx4sUkJiZSpcr/pxahoaEMGzaM8ePHEx4ejtVqZcyYMdhsNjp27AhAt27diIuLY+DAgcyePZuMjAwef/xxkpKSSjXk9XtKakRERMQjH3/8MYcPH2bo0KElrs2ZMwcfHx/69etHfn4+CQkJvPzyy87rvr6+JCcnM2rUKGw2G0FBQSQmJjJ9+nS341BSIyIiYiKeDCEV93dXt27dMAzjvNcCAgKYP38+8+fPv2D/2NhYPvjgA7ef+7+U1IiIiJiIAx8cHgw/edK3snlv5CIiIiK/o0qNiIiIidgNC3YPhp886VvZlNSIiIiYSGXMqblUKKkRERExEcPDt3QbHvStbN4buYiIiMjvqFIjIiJiInYs2PFgTo0HfSubkhoRERETcRiezYtxnH+7Ga+g4ScRERExBVVq5LJht8M/n48i9d3qnPqpKjUiC7n5rizuHXsSy+/+UnN4rz9vPBnNf74Mxl4EsY3zmfzaASLqFAIwsV9D/pMW7HLvHgN/5qFnjl7MryPitvvGn2DgX0+6nDuyz5/hnZtVUkRSERweThT2pG9l89qkpkuXLrRu3Zq5c+dW2DPq1avH2LFjGTt27AXbTJs2jTVr1rBjx44Ki0PKx4r5ESQvvYIJfz9MbJM89n4byPPj6hIUYqfP8J8BOH7Qj/F9GnFL/18YOCGDaiF2Du0JwC/AtR7bfcDPDJqY4fzsH+i4qN9FpKwO7g7gkf5XOj/bi7x3/oScnwMLDg/mxXjSt7J5bVJTGSwWC6tXr6ZPnz6VHYqUwa5tQdgSTtMhPgeAqJgCPl1zhj07qjnbLHm6FtfcmMPwySec56LrFZS4l3+gQXhEUcUHLVLO7HY49VPVyg5DpEJ4b41JxE1x7c+y4/MQju4/9yr7/TsD2Lk1iKtvPAOAwwFbU63UbpDP3+5pwF0truLBno3Y/GFoiXt9uqo6d17VnJFdm7DoqVrk/eq9f7ORy0vt+gUs3/49SzbvYtKLh6gZXTJpF+9WvKOwJ4e38uqkxuFw8PDDDxMeHk5UVBTTpk1zXsvOzmb48OHUrFkTq9XKjTfeyLfffuu8vn//fnr37k1kZCTBwcFcffXVfPzxxxd8Vr169QC4/fbbsVgszs/F/vGPf1CvXj1CQ0Pp378/Z86c+0W5bNkyatSoQX5+vkv7Pn36MHDgQM/+AMQtd4/OpHPvUwy/oSk96rYiqVsTbh/xEzf2PQVA9s9V+O2sL/96KYL2Xc8w660fue6W00wfXo//pAU579P19lM8/NIhZq/cR/8xmaS+W53ZY2Ir62uJlNrub4J4blxdHrvvSl58tA5RdfN5fvVeAoPslR2alKPiOTWeHN7KeyMHli5dSlBQEFu2bGH27NlMnz6dlJQUAO68804yMzP58MMP2b59O23btuWmm24iKysLgNzcXHr06EFqairffPMNt9xyC7169eLw4cPnfdZXX30FwOLFizlx4oTzM5xLkNasWUNycjLJycls3LiRp59+2hmH3W7nvffec7bPzMxk7dq1DB069ILfLT8/n5ycHJdDPLPpvTA+WVWdR+YfYv5He5jw98OsXBhByorqABj/nRZjS8ih78ifuLL5b9w9JpMO8TmsXXaF8z497vuF9l3OUL9ZHjf2PcXEvx/miw/DOH7QrzK+lkipbfvUymfJYRxID2T7RiuPD2xAsNXODb2yKzs0kXLh1UlNy5YtmTp1Ko0aNWLQoEG0b9+e1NRUPv/8c7Zu3co777xD+/btadSoEc899xxhYWGsXLkSgFatWvGXv/yF5s2b06hRI2bMmMGVV17pknz8Xs2aNQEICwsjKirK+RnOVYyWLFlC8+bN6dSpEwMHDiQ1NRWAwMBA7r33XhYvXuxs/89//pO6devSpUuXC363WbNmERoa6jxiYmI8/eO67L02I5q7R2fSpU829ZvlEX/HKfqO+Im3X4wEwBpux7eKQWzjPJd+MY3yyDx24TkITdv+CsDxg/4VF7xIBTibU4WjP/oTXS//zxuL13Bgcb7/qUyHF08U9vqk5vdq1apFZmYm3377Lbm5udSoUYPg4GDnceDAAfbv3w+cq9RMmDCBZs2aERYWRnBwMOnp6Res1PyRevXqERISUiKOYiNGjGD9+vUcO3YMgCVLljB48GAslgv/4Dz66KOcPn3aeRw5csTtuMRVfp4PFh/XVUw+vgbGf09V9TNo3OpX55ybYsd+9Hcu5z6f/d8HAhAeceE2IpeigGp2omMLyMrUxGEzMf67+qmsh+HFSY1Xr36qWtX1P0SLxYLD4SA3N5datWqxYcOGEn3CwsIAmDBhAikpKTz33HM0bNiQwMBA7rjjDgoK3J80d6E4irVp04ZWrVqxbNkyunXrxs6dO1m7du0f3tPf3x9/f/3Nvzx1vDmHt+dFElG7kNgmeez/PpBVr0TQrf8vzjZ3PpDJU/fH0rxjLq2uzWXbp1a+TAnl2ZX7gHNLvj9dXZ1rbsohpLqdA7sCeGVabVp0zKVBXN6FHi1ySRgx+RhfpoSSebQqNaKKGPjXE9gdsGFN9coOTcqR3tJtMm3btiUjI4MqVaqUmNBb7IsvvmDw4MHcfvvtwLnKzcGDB//wvlWrVsVuL9uEuuHDhzN37lyOHTtGfHy8hpMqwQNPHmXp7Fq89Ggdsn+pQo3IQnoM/JkB4/5/M7Lrup/mwaeP8vZLkSyYXIc6Dc5tvNe8w1kAqlQ1+OazEFa/XpO8X32oGV3I9T2yuWfsyQs9VuSScUWtQh6df5CQ6nZOZ1Vh59YgxvZqzOksU/4qkMuQKX+S4+Pjsdls9OnTh9mzZ9O4cWOOHz/O2rVruf32253zbFatWkWvXr2wWCxMnjzZpbpyPvXq1SM1NZXrrrsOf39/qlcv/d9u7r33XiZMmMBrr73GsmXLPP2KUgbVgh2Mmn6MUdOP/WG7hHuySLgn67zXImoX8tyqfRURnkiFm/VAvcoOQS6Cy3lHYe+N/A9YLBY++OADbrjhBoYMGULjxo3p378/hw4dIjLy3KTQF154gerVq3PttdfSq1cvEhISaNu27R/e9/nnnyclJYWYmBjatGnjVkyhoaH069eP4OBgbd4nIiIVxqNJwh4OXVU2i2EYXvw+Tu9y0003cdVVVzFv3jy3++bk5BAaGsqpHxpgDTFlLipCQm33/rIg4i2KjEI2GGs4ffo0Vqu1Qp5R/Hui9/qhVA0q+xYThWcL+He3RRUaa0Ux5fDTpebUqVNs2LCBDRs28PLLL1d2OCIiYmJ695NUqDZt2nDq1CmeeeYZmjRpUtnhiIiIiWn1k1SoP1tVJSIiIp5TUiMiImIiqtSIiIiIKVzOSY2W0YiIiIgpqFIjIiJiIpdzpUZJjYiIiIkYeLYs25s3r1NSIyIiYiKXc6VGc2pERETEFJTUiIiImEhlvPvp2LFj3HfffdSoUYPAwEBatGjBtm3bnNcNw2DKlCnUqlWLwMBA4uPj2bt3r8s9srKyGDBgAFarlbCwMIYNG0Zubq5bcSipERERMZGLndScOnWK6667jqpVq/Lhhx+ya9cunn/+eapXr+5sM3v2bObNm8fChQvZsmULQUFBJCQkkJeX52wzYMAAdu7cSUpKCsnJyWzatImRI0e6FYvm1IiIiEgJOTk5Lp/9/f3x9/cv0e6ZZ54hJiaGxYsXO8/Vr1/f+e+GYTB37lwef/xxevfuDcCyZcuIjIxkzZo19O/fn/T0dNatW8dXX31F+/btAXjxxRfp0aMHzz33HNHR0aWKWZUaEREREymvSk1MTAyhoaHOY9asWed93nvvvUf79u258847iYiIoE2bNrz22mvO6wcOHCAjI4P4+HjnudDQUDp06EBaWhoAaWlphIWFORMagPj4eHx8fNiyZUupv7sqNSIiIiZiGBYMD1YwFfc9cuQIVqvVef58VRqAH3/8kQULFjB+/Hj+9re/8dVXX/Hggw/i5+dHYmIiGRkZAERGRrr0i4yMdF7LyMggIiLC5XqVKlUIDw93tikNJTUiIiJSgtVqdUlqLsThcNC+fXueeuopANq0acP333/PwoULSUxMrOgwXWj4SURExEQcWDw+3FGrVi3i4uJczjVr1ozDhw8DEBUVBcDJkydd2pw8edJ5LSoqiszMTJfrRUVFZGVlOduUhpIaERERE7nYq5+uu+469uzZ43Luhx9+IDY2Fjg3aTgqKorU1FTn9ZycHLZs2YLNZgPAZrORnZ3N9u3bnW0++eQTHA4HHTp0KHUsGn4SERGRMhs3bhzXXnstTz31FHfddRdbt27l1Vdf5dVXXwXAYrEwduxYnnzySRo1akT9+vWZPHky0dHR9OnTBzhX2bnlllsYMWIECxcupLCwkNGjR9O/f/9Sr3wCJTUiIiKmUl4ThUvr6quvZvXq1Tz66KNMnz6d+vXrM3fuXAYMGOBs8/DDD3P27FlGjhxJdnY2119/PevWrSMgIMDZ5s0332T06NHcdNNN+Pj40K9fP+bNm+dWLBbDMLz53VWXjZycHEJDQzn1QwOsIRo1FHNKqN2mskMQqRBFRiEbjDWcPn26VJNvy6L490T7VWOpEnT+lUqlUXQ2n21951ZorBVFlRoRERETudiVmkuJ/sovIiIipqBKjYiIiIkYZXwp5e/7eyslNSIiIiZiAJ7MlvXmibYafhIRERFTUKVGRETERBxYsLi5K/D/9vdWSmpERERMRKufRERERLycKjUiIiIm4jAsWDyotniycqqyKakRERExEcPwcPWTFy9/0vCTiIiImIIqNSIiIiZyOU8UVlIjIiJiIkpqRERExBQu54nCmlMjIiIipqBKjYiIiIlczquflNSIiIiYyLmkxpM5NeUYzEWm4ScRERExBVVqRERETESrn0RERMQUjP8envT3Vhp+EhEREVNQpUZERMRENPwkIiIi5nAZjz8pqRERETETDys1eHGlRnNqRERExBRUqRERETER7SgsIiIipnA5TxTW8JOIiIiYgio1IiIiZmJYPJvs68WVGiU1IiIiJnI5z6nR8JOIiIiYgpIaERERMzHK4XDDtGnTsFgsLkfTpk2d1/Py8khKSqJGjRoEBwfTr18/Tp486XKPw4cP07NnT6pVq0ZERAQTJ06kqKjI7a+u4ScRERETqYzVT1dddRUff/yx83OVKv+fXowbN461a9fyzjvvEBoayujRo+nbty9ffPEFAHa7nZ49exIVFcXmzZs5ceIEgwYNomrVqjz11FNuxVGqpOa9994r9Q1vu+02twIQERER71alShWioqJKnD99+jRvvPEGy5cv58YbbwRg8eLFNGvWjC+//JKOHTuyfv16du3axccff0xkZCStW7dmxowZTJo0iWnTpuHn51f6OErTqE+fPqW6mcViwW63l/rhIiIiUgHKYbJvTk6Oy2d/f3/8/f3P23bv3r1ER0cTEBCAzWZj1qxZ1K1bl+3bt1NYWEh8fLyzbdOmTalbty5paWl07NiRtLQ0WrRoQWRkpLNNQkICo0aNYufOnbRp06bUMZdqTo3D4SjVoYRGRESkchUPP3lyAMTExBAaGuo8Zs2add7ndejQgSVLlrBu3ToWLFjAgQMH6NSpE2fOnCEjIwM/Pz/CwsJc+kRGRpKRkQFARkaGS0JTfL34mjs8mlOTl5dHQECAJ7cQERGR8lROb+k+cuQIVqvVefpCVZru3bs7/71ly5Z06NCB2NhYVqxYQWBgoAeBuM/t1U92u50ZM2ZQu3ZtgoOD+fHHHwGYPHkyb7zxRrkHKCIiIhef1Wp1OS6U1PyvsLAwGjduzL59+4iKiqKgoIDs7GyXNidPnnTOwYmKiiqxGqr48/nm6fwRt5OamTNnsmTJEmbPnu0yead58+a8/vrr7t5OREREypWlHI6yy83NZf/+/dSqVYt27dpRtWpVUlNTndf37NnD4cOHsdlsANhsNr777jsyMzOdbVJSUrBarcTFxbn1bLeTmmXLlvHqq68yYMAAfH19nedbtWrF7t273b2diIiIlKeLvE/NhAkT2LhxIwcPHmTz5s3cfvvt+Pr6cs899xAaGsqwYcMYP348n376Kdu3b2fIkCHYbDY6duwIQLdu3YiLi2PgwIF8++23fPTRRzz++OMkJSWVujpUzO05NceOHaNhw4YlzjscDgoLC929nYiIiHixo0ePcs899/DLL79Qs2ZNrr/+er788ktq1qwJwJw5c/Dx8aFfv37k5+eTkJDAyy+/7Ozv6+tLcnIyo0aNwmazERQURGJiItOnT3c7FreTmri4OD777DNiY2Ndzq9cudKtZVciIiJSAcpponBpvf322394PSAggPnz5zN//vwLtomNjeWDDz5w78Hn4XZSM2XKFBITEzl27BgOh4NVq1axZ88eli1bRnJysscBiYiIiAcu47d0uz2npnfv3rz//vt8/PHHBAUFMWXKFNLT03n//fe5+eabKyJGERERkT9Vpn1qOnXqREpKSnnHIiIiIh4yjHOHJ/29VZk339u2bRvp6enAuXk27dq1K7egREREpIwu8pyaS4nbSU3xLOcvvvjCue1xdnY21157LW+//TZ16tQp7xhFRERE/pTbc2qGDx9OYWEh6enpZGVlkZWVRXp6Og6Hg+HDh1dEjCIiIlJaxROFPTm8lNuVmo0bN7J582aaNGniPNekSRNefPFFOnXqVK7BiYiIiHssxrnDk/7eyu2kJiYm5ryb7NntdqKjo8slKBERESmjy3hOjdvDT88++yxjxoxh27ZtznPbtm3joYce4rnnnivX4ERERERKq1SVmurVq2Ox/P8Y29mzZ+nQoQNVqpzrXlRURJUqVRg6dCh9+vSpkEBFRESkFC7jzfdKldTMnTu3gsMQERGRcnEZDz+VKqlJTEys6DhEREREPFLmzfcA8vLyKCgocDlntVo9CkhEREQ8cBlXatyeKHz27FlGjx5NREQEQUFBVK9e3eUQERGRSmSUw+Gl3E5qHn74YT755BMWLFiAv78/r7/+Ok888QTR0dEsW7asImIUERER+VNuDz+9//77LFu2jC5dujBkyBA6depEw4YNiY2N5c0332TAgAEVEaeIiIiUxmW8+sntSk1WVhYNGjQAzs2fycrKAuD6669n06ZN5RudiIiIuKV4R2FPDm/ldlLToEEDDhw4AEDTpk1ZsWIFcK6CU/yCSxEREZGLze2kZsiQIXz77bcAPPLII8yfP5+AgADGjRvHxIkTyz1AERERccNlPFHY7Tk148aNc/57fHw8u3fvZvv27TRs2JCWLVuWa3AiIiIipeXRPjUAsbGxxMbGlkcsIiIi4iELHr6lu9wiufhKldTMmzev1Dd88MEHyxyMiIiISFmVKqmZM2dOqW5msViU1FSwzk8Ow9cvoLLDEKkQNYy0yg5BpGIYF3GiymW8pLtUSU3xaicRERG5xOk1CSIiIiLezeOJwiIiInIJuYwrNUpqRERETMTTXYEvqx2FRURERC5FqtSIiIiYyWU8/FSmSs1nn33Gfffdh81m49ixYwD84x//4PPPPy/X4ERERMRNl/FrEtxOat59910SEhIIDAzkm2++IT8/H4DTp0/z1FNPlXuAIiIiIqXhdlLz5JNPsnDhQl577TWqVq3qPH/dddfx9ddfl2twIiIi4p7iicKeHN7K7aRmz5493HDDDSXOh4aGkp2dXR4xiYiISFkV7yjsyeGBp59+GovFwtixY53n8vLySEpKokaNGgQHB9OvXz9Onjzp0u/w4cP07NmTatWqERERwcSJEykqKnLr2W4nNVFRUezbt6/E+c8//5wGDRq4ezsREREpT5U4p+arr77ilVdeoWXLli7nx40bx/vvv88777zDxo0bOX78OH379nVet9vt9OzZk4KCAjZv3szSpUtZsmQJU6ZMcev5bic1I0aM4KGHHmLLli1YLBaOHz/Om2++yYQJExg1apS7txMRERETyM3NZcCAAbz22mtUr17def706dO88cYbvPDCC9x44420a9eOxYsXs3nzZr788ksA1q9fz65du/jnP/9J69at6d69OzNmzGD+/PkUFBSUOga3k5pHHnmEe++9l5tuuonc3FxuuOEGhg8fzl/+8hfGjBnj7u1ERESkHJXXnJqcnByXo3hh0IUkJSXRs2dP4uPjXc5v376dwsJCl/NNmzalbt26pKWde4ltWloaLVq0IDIy0tkmISGBnJwcdu7cWerv7vY+NRaLhccee4yJEyeyb98+cnNziYuLIzg42N1biYiISHkrp31qYmJiXE5PnTqVadOmnbfL22+/zddff81XX31V4lpGRgZ+fn6EhYW5nI+MjCQjI8PZ5vcJTfH14mulVebN9/z8/IiLiytrdxEREbmEHTlyBKvV6vzs7+9/wXYPPfQQKSkpBAQEXKzwzsvtpKZr165YLBeeGf3JJ594FJCIiIh4wNNl2f/ta7VaXZKaC9m+fTuZmZm0bdvWec5ut7Np0yZeeuklPvroIwoKCsjOznap1pw8eZKoqCjg3CKkrVu3uty3eHVUcZvScDupad26tcvnwsJCduzYwffff09iYqK7txMREZHydJFfk3DTTTfx3XffuZwbMmQITZs2ZdKkScTExFC1alVSU1Pp168fcG57mMOHD2Oz2QCw2WzMnDmTzMxMIiIiAEhJScFqtbo1KuR2UjNnzpzznp82bRq5ubnu3k5ERES8WEhICM2bN3c5FxQURI0aNZznhw0bxvjx4wkPD8dqtTJmzBhsNhsdO3YEoFu3bsTFxTFw4EBmz55NRkYGjz/+OElJSRcc9jqfcntL93333ceiRYvK63YiIiJSFpfgu5/mzJnDrbfeSr9+/bjhhhuIiopi1apVzuu+vr4kJyfj6+uLzWbjvvvuY9CgQUyfPt2t55TbW7rT0tIqfYKQiIjI5c7TVx2Ux2sSNmzY4PI5ICCA+fPnM3/+/Av2iY2N5YMPPvDouW4nNb/fARDAMAxOnDjBtm3bmDx5skfBiIiIiJSV20lNaGioy2cfHx+aNGnC9OnT6datW7kFJiIiIuIOt5Iau93OkCFDaNGihcsWyCIiInKJuMirny4lbk0U9vX1pVu3bnobt4iIyCWqvF6T4I3cXv3UvHlzfvzxx4qIRURERKTM3E5qnnzySSZMmEBycjInTpwo8cIrERERqWSX0HLui6nUc2qmT5/OX//6V3r06AHAbbfd5vK6BMMwsFgs2O328o9SRERESucynlNT6qTmiSee4P777+fTTz+tyHhEREREyqTUSY1hnEvdOnfuXGHBiIiIiGcuhc33KotbS7r/6O3cIiIicgnQ8FPpNG7c+E8Tm6ysLI8CEhERESkLt5KaJ554osSOwiIiInLp0PBTKfXv35+IiIiKikVEREQ8dRkPP5V6nxrNpxEREZFLmdurn0REROQSdhlXakqd1DgcjoqMQ0RERMqB5tSIiIiIOVzGlRq33/0kIiIicilSpUZERMRMLuNKjZIaERERE7mc59Ro+ElERERMQZUaERERM9Hwk4iIiJiBhp9EREREvJwqNSIiImai4ScRERExhcs4qdHwk4iIiJiCKjUiIiImYvnv4Ul/b6WkRkRExEwu4+EnJTUiIiImoiXdIiIiIl5OlRoREREzuYyHn1SpERERMRvDg8NNCxYsoGXLllitVqxWKzabjQ8//NB5PS8vj6SkJGrUqEFwcDD9+vXj5MmTLvc4fPgwPXv2pFq1akRERDBx4kSKiorcjkVJjYiIiJRZnTp1ePrpp9m+fTvbtm3jxhtvpHfv3uzcuROAcePG8f777/POO++wceNGjh8/Tt++fZ397XY7PXv2pKCggM2bN7N06VKWLFnClClT3I5Fw08iIiImcrEnCvfq1cvl88yZM1mwYAFffvklderU4Y033mD58uXceOONACxevJhmzZrx5Zdf0rFjR9avX8+uXbv4+OOPiYyMpHXr1syYMYNJkyYxbdo0/Pz8Sh2LKjUiIiJm4snQ0++GoHJyclyO/Pz8P3203W7n7bff5uzZs9hsNrZv305hYSHx8fHONk2bNqVu3bqkpaUBkJaWRosWLYiMjHS2SUhIICcnx1ntKS0lNSIiIlJCTEwMoaGhzmPWrFkXbPvdd98RHByMv78/999/P6tXryYuLo6MjAz8/PwICwtzaR8ZGUlGRgYAGRkZLglN8fXia+7Q8JOIiIiJlNfw05EjR7Barc7z/v7+F+zTpEkTduzYwenTp1m5ciWJiYls3Lix7EGUkZIaERERMymnJd3Fq5lKw8/Pj4YNGwLQrl07vvrqK/7+979z9913U1BQQHZ2tku15uTJk0RFRQEQFRXF1q1bXe5XvDqquE1pafhJREREypXD4SA/P5927dpRtWpVUlNTndf27NnD4cOHsdlsANhsNr777jsyMzOdbVJSUrBarcTFxbn1XFVqRERETORir3569NFH6d69O3Xr1uXMmTMsX76cDRs28NFHHxEaGsqwYcMYP3484eHhWK1WxowZg81mo2PHjgB069aNuLg4Bg4cyOzZs8nIyODxxx8nKSnpD4e8zkdJjYiIiJlc5B2FMzMzGTRoECdOnCA0NJSWLVvy0UcfcfPNNwMwZ84cfHx86NevH/n5+SQkJPDyyy87+/v6+pKcnMyoUaOw2WwEBQWRmJjI9OnT3Q5dSY2IiIiZXOSk5o033vjD6wEBAcyfP5/58+dfsE1sbCwffPCBew8+D82pEREREVNQpUZERMRELvacmkuJkhoREREz0Vu6RURERLybKjUiIiImYjEMLEbZyy2e9K1sSmpERETMRMNPIiIiIt5NlRoRERET0eonERERMQcNP4mIiIh4N1VqRERETETDTyIiImIOl/Hwk5IaERERE7mcKzWaUyMiIiKmoEqNiIiImWj4SURERMzCm4eQPKHhJxERETEFVWpERETMxDDOHZ7091JKakRERExEq59EREREvJwqNSIiImai1U8iIiJiBhbHucOT/t5Kw08iIiJiCqrUyGVj8A1f07XZAerVzCa/0Jf/HInixfUdOfRzGAC1wnJ4/6/Lz9t30ts3k7rzSgDiamcy+uYtNIv+CQPYeTSCees7sjfjiov0TUQ802vwz9wxKpPwmkX8uCuQlx+vzZ4d1So7LCkvGn4SMb+29U7wztar2HUsAl8fB0nxW3kpMZk7591NXmFVTp4OJuGZQS59bm+/i4HXf8vmvXUBCPQrZN6gtWzaXY9nkjvh6+PgLzdu48VBa+n53H3YHb6V8dVESq3zbacYOfU4Lz5Sh91fV+P2ET8xc/mPDOvUhNO/VK3s8KQcaPVTJcrIyGDMmDE0aNAAf39/YmJi6NWrF6mpqc42mzdvpkePHlSvXp2AgABatGjBCy+8gN1uB+Ddd9/F19eXY8eOnfcZjRo1Yvz48QB06dKFsWPHOq916dIFi8WCxWLB39+f2rVr06tXL1atWlWq+B988EHatWuHv78/rVu3Pm+bFStW0Lp1a6pVq0ZsbCzPPvtsqe4t5evBZT1J/qYpP2aGszfjCqat6kqtsFyaRf8EgMPw4Zfcai5H17gDfPz9lfxWcO5/9vWuOEVYtXxeSb2aQz+H8WNmOK9+2o4rQn6jVlhuZX49kVLpO/Jn1i0PZ/2/wjm8N4B5k+qQ/5uFhHuyKjs0KS/F+9R4cnipSk1qDh48SLt27fjkk0949tln+e6771i3bh1du3YlKSkJgNWrV9O5c2fq1KnDp59+yu7du3nooYd48skn6d+/P4ZhcNttt1GjRg2WLl1a4hmbNm1i3759DBs27IJxjBgxghMnTrB//37effdd4uLi6N+/PyNHjizV9xg6dCh33333ea99+OGHDBgwgPvvv5/vv/+el19+mTlz5vDSSy+V6t5ScYIDCgDI+S3gvNebRv9Ek1q/8O/tTZ3nDv0cRvbZAHq3S6eKrx3/KkX0brubHzOrcyI75KLELVJWVao6aNTyV77+7P9/Vg3DwjefhRDX7tdKjEykfFTq8NMDDzyAxWJh69atBAUFOc9fddVVDB06lLNnzzJixAhuu+02Xn31Vef14cOHExkZyW233caKFSu4++67GThwIEuWLOFvf/ubyzMWLVpEhw4duOqqqy4YR7Vq1YiKigKgTp06dOzYkaZNmzJ06FDuuusu4uPjL9h33rx5APz000/85z//KXH9H//4B3369OH+++8HoEGDBjz66KM888wzJCUlYbFYznvf/Px88vPznZ9zcnIuGIO4z2Ix+GuPL9hxKIr9meHnbdO7bTo/ZlbnP0einOd+LfDjL4tu47l71zGsy9cAHPkllNFLe2J3VHrhU+QPWcPt+FaB7J9c/9d/6ucqxDTMv0Av8TYafqoEWVlZrFu3jqSkJJeEplhYWBjr16/nl19+YcKECSWu9+rVi8aNG/PWW28BMGzYMPbu3cumTZucbXJzc1m5cuUfVmkuJDExkerVq5d6GOpC8vPzCQhwrQQEBgZy9OhRDh06dMF+s2bNIjQ01HnExMR4FIe4mnTrZ1wZkcXfVpw/YfWvUsQtLfe5VGmKz0/us4FvD0cx5NXbGfZaH/ZnhvP3gR/gX6XoYoQuIvLHjHI4vFSlJTX79u3DMAyaNm16wTY//PADAM2aNTvv9aZNmzrbxMXF0bFjRxYtWuS8vmLFCgzDoH///m7H5+PjQ+PGjTl48KDbfX8vISGBVatWkZqaisPh4IcffuD5558H4MSJExfs9+ijj3L69GnnceTIEY/ikP/3cM/PuL7JIe5fdBuZOcHnbXPTVT8SULWItTsau5y/peVealU/wxOru7LrWATfH43ksXduIrr6GTo3O3gRohcpu5wsX+xFEFbTNQGvfkURp37SuhHxfpWW1BhuTEQqbduhQ4eycuVKzpw5A5wberrzzjsJCSnbXAfDMJzDQ927dyc4OJjg4OA/HMr6XyNGjGD06NHceuut+Pn50bFjR2eS5eNz4T9+f39/rFaryyGeMni452d0iTvAqEW9OJ594T/T3u3S2bSnHtm/BrqcD6hahGFYXObRFX+2eHPNVi4LRYU+7P1PNdpcf8Z5zmIxaH19Lru2a0m3WRQPP3lyeKtKS2oaNWqExWJh9+7dF2zTuPG5vyWnp6ef93p6erqzDeBMFlasWMHevXv54osvyjT0BGC329m7dy/169cH4PXXX2fHjh3s2LGDDz74oNT3sVgsPPPMM+Tm5nLo0CEyMjK45pprgHPza+TimXTrZ3RvtZfH34nn1wI/agT/So3gX0sMG9UJP02b2BOs2Vayivjl/jqEBOQz6dbPqFfzFA0isph6+6fYHT5s+zH6Yn0VkTJb9eoVdL83i/g7s4hpmMeYp48SUM3B+rfPP7dMvJBWP1184eHhJCQkMH/+fM6ePVvienZ2Nt26dSM8PNw5XPN77733Hnv37uWee+5xngsJCeHOO+9k0aJFLF68mMaNG9OpU6cyxbd06VJOnTpFv379AKhduzYNGzakYcOGxMbGun0/X19fateujZ+fH2+99RY2m42aNWuWKTYpmzs77CIksIBXh73HR5OWOY+bW+xzaXdb291k5gTz5f6S85gO/Vyd8W/eQqOoLBaPWM1rw/7NFSG/MmZZT37JLTk3TORSs/G96rw2I5pBEzN4OeUHrrwqj8cG1Cf7Z+1RI2Uza9Ysrr76akJCQoiIiKBPnz7s2bPHpU1eXh5JSUnUqFGD4OBg+vXrx8mTJ13aHD58mJ49e1KtWjUiIiKYOHEiRUXuzVWs1EHU+fPnc91113HNNdcwffp0WrZsSVFRESkpKSxYsID09HReeeUV5/Lq0aNHY7VaSU1NZeLEidxxxx3cddddLvccNmwYnTp1Ij09nUmTJpUqjl9//ZWMjAyKioo4evQoq1evZs6cOYwaNYquXbv+Yd99+/aRm5tLRkYGv/32Gzt27ADOzfHx8/Pj559/ZuXKlXTp0oW8vDwWL17MO++8w8aNG8v0ZyZl137y/aVq9/LHHXj54w4XvL5lfwxbzpPwiHiL9xZfwXuLtQO2WV3s1U8bN24kKSmJq6++mqKiIv72t7/RrVs3du3a5VwING7cONauXcs777xDaGgoo0ePpm/fvnzxxRfAudGRnj17EhUVxebNmzlx4gSDBg2iatWqPPXUU27E7s7klgpw4sQJZs6cSXJyMidOnKBmzZq0a9eOcePG0aVLFwA+++wzZs6cSVpaGnl5eTRq1IghQ4YwduxYfH1L7uDatGlT9u3bx5EjR6hVq5bLtS5dutC6dWvmzp3r/FycYPj5+VGjRg3atWvH0KFDuf322/80/t/3/70DBw5Qr149fv75Z3r16sV3332HYRjYbDZmzpxJhw4X/qV5Pjk5OYSGhtJy0Ex8/c6/r4qIt6vxRlplhyBSIYqMQjbwb06fPl1hcySLf0/YbplOlapl/z1RVJhH2ropHDlyxCVWf39//P39/7T/Tz/9REREBBs3buSGG27g9OnT1KxZk+XLl3PHHXcAsHv3bpo1a0ZaWhodO3bkww8/5NZbb+X48eNERkYCsHDhQiZNmsRPP/2En59fqWKv9OnutWrV4qWXXvrDzeg6derEunXrSn3PP5qns2HDhj/87K4/63/FFVeQlqb/UYuIiHf5361Epk6dyrRp0/603+nTp4Fz00wAtm/fTmFhocueb02bNqVu3brOpCYtLY0WLVo4Exo4t3p41KhR7Ny5kzZt2pQq5kpPakRERKT8lNfw0/kqNX/G4XAwduxYrrvuOpo3bw6cex2Sn58fYWFhLm0jIyPJyMhwtvl9QlN8vfhaaSmpERERMROHce7wpD+UaTuRpKQkvv/+ez7//POyP98D2tddRETETCppR+HRo0eTnJzMp59+Sp06dZzno6KiKCgoIDs726X9yZMnna8oioqKKrEaqvhzcZvSUFIjIiIiZWYYBqNHj2b16tV88sknzv3dirVr146qVauSmprqPLdnzx4OHz6MzWYDwGaz8d1335GZmelsk5KSgtVqJS4urtSxaPhJRETERCx4OKfGzfZJSUksX76cf//734SEhDjnwISGhhIYGEhoaCjDhg1j/PjxhIeHY7VaGTNmDDabjY4dOwLQrVs34uLiGDhwILNnzyYjI4PHH3+cpKSkUs3lKaakRkRExEw83RXYzb4LFiwAcG7DUmzx4sUMHjwYgDlz5uDj40O/fv3Iz88nISGBl19+2dnW19eX5ORkRo0ahc1mIygoiMTERKZPn+5WLEpqREREpMxKs91dQEAA8+fPZ/78+RdsExsb69ZriM5HSY2IiIiJXOwdhS8lSmpERETMxIMVTM7+Xkqrn0RERMQUVKkRERExEYthYPFgorAnfSubkhoREREzcfz38KS/l9Lwk4iIiJiCKjUiIiImouEnERERMYfLePWTkhoREREzucg7Cl9KNKdGRERETEGVGhERERPRjsIiIiJiDhp+EhEREfFuqtSIiIiYiMVx7vCkv7dSUiMiImImGn4SERER8W6q1IiIiJiJNt8TERERM7icX5Og4ScRERExBVVqREREzOQyniispEZERMRMDMCTZdnem9MoqRERETETzakRERER8XKq1IiIiJiJgYdzasotkotOSY2IiIiZXMYThTX8JCIiIqagSo2IiIiZOACLh/29lJIaERERE9HqJxEREREvp0qNiIiImVzGE4WV1IiIiJjJZZzUaPhJREREPLJp0yZ69epFdHQ0FouFNWvWuFw3DIMpU6ZQq1YtAgMDiY+PZ+/evS5tsrKyGDBgAFarlbCwMIYNG0Zubq5bcSipERERMZPiSo0nh5vOnj1Lq1atmD9//nmvz549m3nz5rFw4UK2bNlCUFAQCQkJ5OXlOdsMGDCAnTt3kpKSQnJyMps2bWLkyJFuxaHhJxERETOphCXd3bt3p3v37ue9ZhgGc+fO5fHHH6d3794ALFu2jMjISNasWUP//v1JT09n3bp1fPXVV7Rv3x6AF198kR49evDcc88RHR1dqjhUqRERETGR4iXdnhwAOTk5Lkd+fn6Z4jlw4AAZGRnEx8c7z4WGhtKhQwfS0tIASEtLIywszJnQAMTHx+Pj48OWLVtK/SwlNSIiIlJCTEwMoaGhzmPWrFlluk9GRgYAkZGRLucjIyOd1zIyMoiIiHC5XqVKFcLDw51tSkPDTyIiImZSTqufjhw5gtVqdZ729/f3NLIKp6RGRETETBwGWDxIahzn+lqtVpekpqyioqIAOHnyJLVq1XKeP3nyJK1bt3a2yczMdOlXVFREVlaWs39paPhJREREKkz9+vWJiooiNTXVeS4nJ4ctW7Zgs9kAsNlsZGdns337dmebTz75BIfDQYcOHUr9LFVqREREzKQSNt/Lzc1l3759zs8HDhxgx44dhIeHU7duXcaOHcuTTz5Jo0aNqF+/PpMnTyY6Opo+ffoA0KxZM2655RZGjBjBwoULKSwsZPTo0fTv37/UK59ASY2IiIjJeJjU4H7fbdu20bVrV+fn8ePHA5CYmMiSJUt4+OGHOXv2LCNHjiQ7O5vrr7+edevWERAQ4Ozz5ptvMnr0aG666SZ8fHzo168f8+bNcysOJTUiIiLikS5dumD8QSJlsViYPn0606dPv2Cb8PBwli9f7lEcSmpERETM5DJ+95OSGhERETNxGJRlCMm1v3fS6icRERExBVVqREREzMRwnDs86e+llNSIiIiYiebUiIiIiCloTo2IiIiId1OlRkRExEw0/CQiIiKmYOBhUlNukVx0Gn4SERERU1ClRkRExEw0/CQiIiKm4HAAHuw14/DefWo0/CQiIiKmoEqNiIiImWj4SUREREzhMk5qNPwkIiIipqBKjYiIiJlcxq9JUFIjIiJiIobhwPDgTdue9K1sSmpERETMxDA8q7ZoTo2IiIhI5VKlRkRExEwMD+fUeHGlRkmNiIiImTgcYPFgXowXz6nR8JOIiIiYgio1IiIiZqLhJxERETEDw+HA8GD4yZuXdGv4SURERExBlRoREREz0fCTiIiImILDAMvlmdRo+ElERERMQZUaERERMzEMwJN9ary3UqOkRkRExEQMh4HhwfCToaRGRERELgmGA88qNVrSLSIiIpex+fPnU69ePQICAujQoQNbt2696DEoqRERETERw2F4fLjrX//6F+PHj2fq1Kl8/fXXtGrVioSEBDIzMyvgG16YkhoREREzMRyeH2564YUXGDFiBEOGDCEuLo6FCxdSrVo1Fi1aVAFf8MI0p8ZLFE/cshfkVXIkIhWnyCis7BBEKkQR5362L8Yk3CIKPdp7rzjWnJwcl/P+/v74+/uXaF9QUMD27dt59NFHned8fHyIj48nLS2t7IGUgZIaL3HmzBkAdr49o5IjERGRsjpz5gyhoaEVcm8/Pz+ioqL4POMDj+8VHBxMTEyMy7mpU6cybdq0Em1//vln7HY7kZGRLucjIyPZvXu3x7G4Q0mNl4iOjubIkSOEhIRgsVgqOxzTy8nJISYmhiNHjmC1Wis7HJFyp5/xi8swDM6cOUN0dHSFPSMgIIADBw5QUFDg8b0Mwyjxu+Z8VZpLjZIaL+Hj40OdOnUqO4zLjtVq1f/wxdT0M37xVFSF5vcCAgIICAio8Of83hVXXIGvry8nT550OX/y5EmioqIuaiyaKCwiIiJl5ufnR7t27UhNTXWeczgcpKamYrPZLmosqtSIiIiIR8aPH09iYiLt27fnmmuuYe7cuZw9e5YhQ4Zc1DiU1Iich7+/P1OnTvWKMWSRstDPuJSnu+++m59++okpU6aQkZFB69atWbduXYnJwxXNYnjzSx5ERERE/ktzakRERMQUlNSIiIiIKSipEREREVNQUiNeqUuXLowdO7ZCn1GvXj3mzp37h22mTZtG69atKzQOEREpHSU1IqVksVhYs2ZNZYchJpORkcGYMWNo0KAB/v7+xMTE0KtXL5c9PzZv3kyPHj2oXr06AQEBtGjRghdeeAG73Q7Au+++i6+vL8eOHTvvMxo1asT48eOBkn8h6NKlCxaLBYvFgr+/P7Vr16ZXr16sWrWqVPE/+OCDtGvXDn9//wsm+CtWrKB169ZUq1aN2NhYnn322VLdW8RdSmpERCrJwYMHadeuHZ988gnPPvss3333HevWraNr164kJSUBsHr1ajp37kydOnX49NNP2b17Nw899BBPPvkk/fv3xzAMbrvtNmrUqMHSpUtLPGPTpk3s27ePYcOGXTCOESNGcOLECfbv38+7775LXFwc/fv3Z+TIkaX6HkOHDuXuu+8+77UPP/yQAQMGcP/99/P999/z8ssvM2fOHF566aVS3VvELYaIF+rcubMxZswYY+LEiUb16tWNyMhIY+rUqc7rp06dMoYNG2ZcccUVRkhIiNG1a1djx44dzuv79u0zbrvtNiMiIsIICgoy2rdvb6SkpLg8IzY21pgzZ47z3zn33lsDMGJjYw3DMIypU6carVq1MpYtW2bExsYaVqvVuPvuu42cnBzDMAxj6dKlRnh4uJGXl+dy7969exv33Xdf+f/BiFfp3r27Ubt2bSM3N7fEtVOnThm5ublGjRo1jL59+5a4/t577xmA8fbbbxuGYRjjx483GjVqVKJdYmKi0aFDB+fnzp07Gw899NAFPxdbtGiRAZT47+JCiv9b+F/33HOPcccdd7icmzdvnlGnTh3D4XCU6t4ipaVKjXitpUuXEhQUxJYtW5g9ezbTp08nJSUFgDvvvJPMzEw+/PBDtm/fTtu2bbnpppvIysoCIDc3lx49epCamso333zDLbfcQq9evTh8+PB5n/XVV18BsHjxYk6cOOH8DLB//37WrFlDcnIyycnJbNy4kaefftoZh91u57333nO2z8zMZO3atQwdOrRC/lzEO2RlZbFu3TqSkpIICgoqcT0sLIz169fzyy+/MGHChBLXe/XqRePGjXnrrbcAGDZsGHv37mXTpk3ONrm5uaxcufIPqzQXkpiYSPXq1Us9DHUh+fn5Jd5FFBgYyNGjRzl06JBH9xb5X0pqxGu1bNmSqVOn0qhRIwYNGkT79u1JTU3l888/Z+vWrbzzzju0b9+eRo0a8dxzzxEWFsbKlSsBaNWqFX/5y19o3rw5jRo1YsaMGVx55ZUuycfv1axZEzj3iyYqKsr5Gc6942TJkiU0b96cTp06MXDgQOd8iMDAQO69914WL17sbP/Pf/6TunXr0qVLlwr6kxFvsG/fPgzDoGnTphds88MPPwDQrFmz815v2rSps01cXBwdO3Zk0aJFzusrVqzAMAz69+/vdnw+Pj40btyYgwcPut339xISEli1ahWpqak4HA5++OEHnn/+eQBOnDjh0b1F/peSGvFaLVu2dPlcq1YtMjMz+fbbb8nNzaVGjRoEBwc7jwMHDrB//37g3N9gJ0yYQLNmzQgLCyM4OJj09PQLVmr+SL169QgJCSkRR7ERI0awfv165yTOJUuWMHjwYCwWS1m+tpiE4cZm7qVtO3ToUFauXMmZM2cAWLRoEXfeeafLz6e7MRb/nHbv3t3539JVV11V6nuMGDGC0aNHc+utt+Ln50fHjh2dSZaPj34FSfnSu5/Ea1WtWtXls8ViweFwkJubS61atdiwYUOJPmFhYQBMmDCBlJQUnnvuORo2bEhgYCB33HEHBQUF5RZHsTZt2tCqVSuWLVtGt27d2LlzJ2vXrnX7OWIujRo1wmKxsHv37gu2ady4MQDp6elce+21Ja6np6cTFxfn/Ny/f3/GjRvHihUruOGGG/jiiy+YNWtWmeKz2+3s3buXq6++GoDXX3+d3377DSj5M/9HLBYLzzzzDE899RQZGRnUrFnTWcls0KBBmWITuRAlNWI6bdu2JSMjgypVqlCvXr3ztvniiy8YPHgwt99+O3CucvNnZfaqVas6l9C6a/jw4cydO5djx44RHx9PTExMme4j5hEeHk5CQgLz58/nwQcfLDGvJjs7m27duhEeHs7zzz9fIql577332Lt3LzNmzHCeCwkJ4c4772TRokXs37+fxo0b06lTpzLFt3TpUk6dOkW/fv0AqF27dpnuU8zX19d5j7feegubzeYyjCtSHlT7E9OJj4/HZrPRp08f1q9fz8GDB9m8eTOPPfYY27ZtA879LXnVqlXs2LGDb7/9lnvvvdelunI+9erVIzU1lYyMDE6dOuVWTPfeey9Hjx7ltdde0wRhcZo/fz52u51rrrmGd999l71795Kens68efOw2WwEBQXxyiuv8O9//5uRI0fyn//8h4MHD/LGG28wePBg7rjjDu666y6Xew4bNozNmzezcOHCUv+s/frrr2RkZHD06FG+/PJLJk2axP3338+oUaPo2rXrH/bdt28fO3bsICMjg99++40dO3awY8cOZ9Xz559/ZuHChezevZsdO3bw0EMP8c477/zpxpYiZaGkRkzHYrHwwQcfcMMNNzBkyBAaN25M//79OXToEJGRkQC88MILVK9enWuvvZZevXqRkJBA27Zt//C+zz//PCkpKcTExNCmTRu3YgoNDaVfv34EBwfTp0+fsn41MZkGDRrw9ddf07VrV/7617/SvHlzbr75ZlJTU1mwYAEAd9xxB59++imHDx+mU6dONGnShDlz5vDYY4/x9ttvl5ibdf3119OkSRNycnIYNGhQqeJ47bXXqFWrFldeeSV9+/Zl165d/Otf/+Lll1/+077Dhw+nTZs2vPLKK/zwww+0adOGNm3acPz4cWebpUuX0r59e6677jp27tzJhg0buOaaa9z4kxIpHYvhzmw1ESmzm266iauuuop58+ZVdigiIqakpEakgp06dYoNGzZwxx13sGvXLpo0aVLZIYmImJImCotUsDZt2nDq1CmeeeYZJTQiIhVIlRoRERExBU0UFhEREVNQUiMiIiKmoKRGRERETEFJjYiIiJiCkhoRERExBSU1IlJqgwcPdtkRuUuXLowdO/aix7FhwwYsFgvZ2dkXbGOxWFizZk2p7zlt2jRat27tUVwHDx7EYrGwY8cOj+4jImWjpEbEyw0ePBiLxYLFYsHPz4+GDRsyffp0ioqKKvzZq1atcnmh4h8pTSIiIuIJbb4nYgK33HILixcvJj8/nw8++ICkpCSqVq3Ko48+WqJtQUEBfn5+5fLc8PDwcrmPiEh5UKVGxAT8/f2JiooiNjaWUaNGER8fz3vvvQf8/5DRzJkziY6Odu5qfOTIEe666y7CwsIIDw+nd+/eHDx40HlPu93O+PHjCQsLo0aNGjz88MP8716d/zv8lJ+fz6RJk4iJicHf35+GDRvyxhtvcPDgQefbnqtXr47FYmHw4MEAOBwOZs2aRf369QkMDKRVq1asXLnS5TkffPABjRs3JjAwkK5du7rEWVqTJk2icePGVKtWjQYNGjB58mQKCwtLtHvllVeIiYmhWrVq3HXXXZw+fdrl+uuvv06zZs0ICAigadOmpXrpo4hcHEpqREwoMDCQgoIC5+fU1FT27NlDSkoKycnJFBYWkpCQQEhICJ999hlffPEFwcHB3HLLLc5+zz//PEuWLGHRokV8/vnnZGVlsXr16j987qBBg3jrrbeYN28e6enpvPLKKwQHBxMTE8O7774LwJ49ezhx4gR///vfAZg1axbLli1j4cKF7Ny5k3HjxnHfffexceNG4Fzy1bdvX3r16sWOHTsYPnw4jzzyiNt/JiEhISxZsoRdu3bx97//nddee405c+a4tNm3bx8rVqzg/fffZ926dXzzzTc88MADzutvvvkmU6ZMYebMmaSnp/PUU08xefJkli5d6nY8IlIBDBHxaomJiUbv3r0NwzAMh8NhpKSkGP7+/saECROc1yMjI438/Hxnn3/84x9GkyZNDIfD4TyXn59vBAYGGh999JFhGIZRq1YtY/bs2c7rhYWFRp06dZzPMgzD6Ny5s/HQQw8ZhmEYe/bsMQAjJSXlvHF++umnBmCcOnXKeS4vL8+oVq2asXnzZpe2w4YNM+655x7DMAzj0UcfNeLi4lyuT5o0qcS9/hdgrF69+oLXn332WaNdu3bOz1OnTjV8fX2No0ePOs99+OGHho+Pj3HixAnDMAzjyiuvNJYvX+5ynxkzZhg2m80wDMM4cOCAARjffPPNBZ8rIhVHc2pETCA5OZng4GAKCwtxOBzce++9TJs2zXm9RYsWLvNovv32W/bt20dISIjLffLy8ti/fz+nT5/mxIkTdOjQwXmtSpUqtG/fvsQQVLEdO3bg6+tL586dSx33vn37+PXXX7n55ptdzhcUFNCmTRsA0tPTXeIAsNlspX5GsX/961/MmzeP/fv3k5ubS1FREVar1aVN3bp1qV27tstzHA4He/bsISQkhP379zNs2DBGjBjhbFNUVERoaKjb8YhI+VNSI2ICXbt2ZcGCBfj5+REdHU2VKq7/aQcFBbl8zs3NpV27drz55psl7lWzZs0yxRAYGOh2n9zcXADWrl3rkkzAuXlC5SUtLY0BAwbwxBNPkJCQQGhoKG+//TbPP/+827G+9tprJZIsX1/fcotVRMpOSY2ICQQFBdGwYcNSt2/bti3/+te/iIiIKFGtKFarVi22bNnCDTfcAJyrSGzfvp22bduet32LFi1wOBxs3LiR+Pj4EteLK0V2u915Li4uDn9/fw4fPnzBCk+zZs2ck56Lffnll3/+JX9n8+bNxMbG8thjjznPHTp0qES7w4cPc/z4caKjo53P8fHxoUmTJkRGRhIdHc2PP/7IgAED3Hq+iFwcmigschkaMGAAV1xxBb179+azzz7jwIEDbNiwgQcffJCjR48C8NBDD/H000+zZs0adu/ezQMPPPCHe8zUq1ePxMREhg4dypo1a5z3XLFiBQCxsbFYLBaSk5P56aefyM3NJSQkhAkTJjBu3DiWLl3K/v37+frrr3nxxRedk2/vv/9+9u7dy8SJE9mzZw/Lly9nyZIlbn3fRo0acfjwYd5++23279/PvHnzzjvpOSAggMTERL799ls+++wzHnzwQe666y6ioqIAeOKJJ5g1axbz5s3jhx9+4LvvvmPx4sW88MILbsUjIhVDSY3IZahatWps2rSJunXr0rdvX5o1a8awYcPIy8tzVm7++te/MnDgQBITE7HZbISEhHD77bf/4X0XLFjAHXfcwQMPPEDTpk0ZMWIEZ8+eBaB27do88cQTPPLII0RGRjJ69GgAZsyYweTJk5k1axbNmjXjlltuYe3atdSvXx84N8/l3XffZc2aNbRq1YqFCxfy1FNPufV9b7vtNsaNG8fo0aNp3bo1mzdvZvLkySXaNWzYkL59+9KjRw+6detGy5YtXZZsDx8+nNdff53FixfTokULOnfuzJIlS5yxikjlshgXmvUnIiIi4kVUqRERERFTUFIjIiIipqCkRkRERExBSY2IiIiYgpIaERERMQUlNSIiImIKSmpERETEFJTUiIiIiCkoqRERERFTUFIjIiIipqCkRkREREzh/wBW1Oo+OOv9SQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cfm = confusion_matrix(trues, preds)\n",
    "#ConfusionMatrixDisplay(cfm, display_labels=['healthy', 'symptomatic', 'COVID-19']).plot()\n",
    "ConfusionMatrixDisplay(cfm, display_labels=['healthy', 'COVID-19']).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "99a40673",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cfm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [64]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcfm\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cfm' is not defined"
     ]
    }
   ],
   "source": [
    "cfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "16a9e3d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0264777",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "a8d9f7fe00d38372c02b25343d92637c9efc1723885c511df4bb7b75b405b5dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
