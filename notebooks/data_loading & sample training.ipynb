{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72bf15ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "# import audiomentations\n",
    "# from audiomentations import Compose, AddGaussianNoise, PitchShift\n",
    "# import torch_audiomentations\n",
    "# from torch_audiomentations import Compose, AddGaussianNoise, PitchShift\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6fe837a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from https://github.com/musikalkemist/pytorchforaudio\n",
    "class CoughDataset(Dataset):\n",
    "\n",
    "    def __init__(self,\n",
    "                 annotations_df,\n",
    "                 audio_dir,\n",
    "                 transformation,\n",
    "                 target_sample_rate,\n",
    "                 num_samples,\n",
    "                 device,\n",
    "                 augment=False,\n",
    "                ):\n",
    "        self.annotations = annotations_df\n",
    "        self.audio_dir = audio_dir\n",
    "        self.device = device\n",
    "        self.transformation = transformation.to(self.device)\n",
    "        self.target_sample_rate = target_sample_rate\n",
    "        self.num_samples = num_samples\n",
    "        self.label_dict = {'healthy':0, 'symptomatic':1, 'COVID-19':2}\n",
    "        \n",
    "        self.do_augment = augment\n",
    "#         self.augmentations = Compose(\n",
    "#                 [\n",
    "#                     AddGaussianNoise(min_amplitude=0.01, max_amplitude=0.05, p=0.5),\n",
    "#                     PitchShift(min_semitones=-8, max_semitones=8, p=0.5)\n",
    "#                 ]\n",
    "#         )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        audio_sample_path = self._get_audio_sample_path(index)\n",
    "        label = self.label_dict[self._get_audio_sample_label(index)]\n",
    "        signal, sr = torchaudio.load(audio_sample_path)\n",
    "        \n",
    "#         if self.do_augment:\n",
    "#             signal = torch.from_numpy(self.augmentations(signal.numpy(), sr))\n",
    "        \n",
    "        signal = signal.to(self.device)\n",
    "        signal = self._resample_if_necessary(signal, sr)\n",
    "        signal = self._mix_down_if_necessary(signal)\n",
    "        signal = self._cut_if_necessary(signal)\n",
    "        signal = self._right_pad_if_necessary(signal)\n",
    "        signal = self.transformation(signal)\n",
    "        \n",
    "        return signal, label\n",
    "\n",
    "    def _cut_if_necessary(self, signal):\n",
    "        if signal.shape[1] > self.num_samples:\n",
    "            signal = signal[:, :self.num_samples]\n",
    "        return signal\n",
    "\n",
    "    def _right_pad_if_necessary(self, signal):\n",
    "        length_signal = signal.shape[1]\n",
    "        if length_signal < self.num_samples:\n",
    "            num_missing_samples = self.num_samples - length_signal\n",
    "            last_dim_padding = (0, num_missing_samples)\n",
    "            signal = torch.nn.functional.pad(signal, last_dim_padding)\n",
    "        return signal\n",
    "\n",
    "    def _resample_if_necessary(self, signal, sr):\n",
    "        if sr != self.target_sample_rate:\n",
    "            resampler = torchaudio.transforms.Resample(sr, self.target_sample_rate)\n",
    "            signal = resampler(signal)\n",
    "        return signal\n",
    "\n",
    "    def _mix_down_if_necessary(self, signal):\n",
    "        if signal.shape[0] > 1:\n",
    "            signal = torch.mean(signal, dim=0, keepdim=True)\n",
    "        return signal\n",
    "\n",
    "    def _get_audio_sample_path(self, index):\n",
    "        path = os.path.join(self.audio_dir, self.annotations.iloc[index, 0])+\".wav\"\n",
    "        return path\n",
    "\n",
    "    def _get_audio_sample_label(self, index):\n",
    "        return self.annotations.iloc[index, 9]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5a17a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_DIR = \"../valid_data/\"\n",
    "SAMPLE_RATE = 16000\n",
    "NUM_SAMPLES = SAMPLE_RATE*10\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "# print(f\"Using device {device}\")\n",
    "\n",
    "# train_df = pd.read_parquet(os.path.join(AUDIO_DIR, \"train.parquet.gzip\"))\n",
    "# val_df = pd.read_parquet(os.path.join(AUDIO_DIR, \"val.parquet.gzip\"))\n",
    "# test_df = pd.read_parquet(os.path.join(AUDIO_DIR, \"test.parquet.gzip\"))\n",
    "\n",
    "train_df = pd.read_parquet(os.path.join(AUDIO_DIR, \"train_edited.parquet.gzip\"))\n",
    "val_df = pd.read_parquet(os.path.join(AUDIO_DIR, \"val_edited.parquet.gzip\"))\n",
    "test_df = pd.read_parquet(os.path.join(AUDIO_DIR, \"test_edited.parquet.gzip\"))\n",
    "\n",
    "# print(f\"There are {len(usd)} samples in the dataset.\")\n",
    "# signal, label = usd[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8045ced4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c258e123",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNNetwork(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, drop_p=0.2):\n",
    "        super().__init__()\n",
    "        # 4 conv blocks / flatten / linear / softmax\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=16,\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "                padding=0\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.Dropout(p=drop_p)\n",
    "\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=16,\n",
    "                out_channels=32,\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "                padding=0\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Dropout(p=drop_p)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=32,\n",
    "                out_channels=64,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=0\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Dropout(p=drop_p)\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=64,\n",
    "                out_channels=128,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=0\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Dropout(p=drop_p)\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear = nn.Linear(31744, 3)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        #nomralization\n",
    "        std = input_data.std()\n",
    "        input_data -= input_data.mean()\n",
    "        input_data /= std\n",
    "        \n",
    "        x = self.conv1(input_data)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear(x)\n",
    "        predictions = self.softmax(logits)\n",
    "        return predictions\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c406986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loader(train_data, batch_size):\n",
    "    train_dataloader = DataLoader(train_data, batch_size=batch_size)\n",
    "    return train_dataloader\n",
    "\n",
    "def count_correct(logits, y_true):\n",
    "    y_pred = torch.argmax(logits, axis = 1)\n",
    "    return torch.sum(y_pred==y_true)\n",
    "\n",
    "def train_single_epoch(model, train_data_loader, val_data_loader, loss_fn, optimiser, device):\n",
    "    total_loss = 0.0\n",
    "    correct_pred = 0.0\n",
    "    total_pred = 0\n",
    "    for x_batch, y_batch in tqdm(train_data_loader):\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        # calculate loss\n",
    "        y_pred = model(x_batch)\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        \n",
    "        correct_pred += count_correct(y_pred, y_batch)\n",
    "        total_pred += y_batch.shape[0]\n",
    "\n",
    "        # backpropagate error and update weights\n",
    "        optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f\"Training loss: {total_loss}, Training accuracy : {correct_pred/total_pred}\")\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    correct_pred = 0.0\n",
    "    total_pred = 0\n",
    "    for x_batch, y_batch in tqdm(val_data_loader):\n",
    "        with torch.no_grad():\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            y_pred = model(x_batch)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            total_loss += loss.item() \n",
    "            \n",
    "        correct_pred += count_correct(y_pred, y_batch)\n",
    "        total_pred += y_batch.shape[0]\n",
    "        \n",
    "    print(f\"Validataion loss: {total_loss}, Validation accuracy : {correct_pred/total_pred}\")\n",
    "\n",
    "    \n",
    "def train(model, train_data_loader, val_data_loader, loss_fn, optimiser, device, epochs):\n",
    "    for i in range(epochs):\n",
    "        print(f\"Epoch {i+1}\")\n",
    "        train_single_epoch(model, train_data_loader, val_data_loader, loss_fn, optimiser, device)\n",
    "        \n",
    "        path = os.path.join(MODEL_FOLDER, f\"epoch_{i}.pth\")\n",
    "        torch.save(model.state_dict(), path)\n",
    "        print(f\"Saved at {path}\")\n",
    "        print(\"---------------------------\")\n",
    "    print(\"Finished training\")\n",
    "    print(\"---------------------------\")\n",
    "    \n",
    "    \n",
    "def evaluate(model, eval_data_loader, loss_fn, device):\n",
    "    print(\"Evaluating model\")\n",
    "    total_loss = 0.0\n",
    "    correct_pred = 0.0\n",
    "    total_pred = 0\n",
    "    for x_batch, y_batch in tqdm(eval_data_loader):\n",
    "        with torch.no_grad():\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            # calculate loss\n",
    "            y_pred = model(x_batch)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "\n",
    "            correct_pred += count_correct(y_pred, y_batch)\n",
    "            total_pred += y_batch.shape[0]\n",
    "\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "    print(f\"Evaluation loss: {total_loss}, Evaluation accuracy : {correct_pred/total_pred}\")\n",
    "    print(\"---------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b393f0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE =16\n",
    "EPOCHS = 10\n",
    "MODEL_FOLDER = '../models/'\n",
    "\n",
    "mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n",
    "    sample_rate=SAMPLE_RATE,\n",
    "    n_fft=1024,\n",
    "    hop_length=512,\n",
    "    n_mels=128\n",
    ")\n",
    "\n",
    "train_data = CoughDataset(train_df,\n",
    "                        AUDIO_DIR,\n",
    "                        mel_spectrogram,\n",
    "                        SAMPLE_RATE,\n",
    "                        NUM_SAMPLES,\n",
    "                        device)\n",
    "\n",
    "val_data = CoughDataset(val_df,\n",
    "                        AUDIO_DIR,\n",
    "                        mel_spectrogram,\n",
    "                        SAMPLE_RATE,\n",
    "                        NUM_SAMPLES,\n",
    "                        device)\n",
    "\n",
    "test_data = CoughDataset(test_df,\n",
    "                        AUDIO_DIR,\n",
    "                        mel_spectrogram,\n",
    "                        SAMPLE_RATE,\n",
    "                        NUM_SAMPLES,\n",
    "                        device)\n",
    "\n",
    "train_dataloader = create_data_loader(train_data, BATCH_SIZE)\n",
    "val_dataloader = create_data_loader(val_data, BATCH_SIZE)\n",
    "test_dataloader = create_data_loader(val_data, BATCH_SIZE)\n",
    "\n",
    "# construct model and assign it to device\n",
    "model = CNNNetwork().to(device)\n",
    "\n",
    "# initialise loss funtion + optimiser\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimiser = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373d65a0",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------------------------------Serena: Data Processing\n",
    "\n",
    "Get all the bad wav files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1f19114",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13535/13535 [00:31<00:00, 434.77it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_df = pd.read_parquet(os.path.join(AUDIO_DIR, \"train.parquet.gzip\"))\n",
    "all_df = pd.read_parquet(os.path.join(AUDIO_DIR, \"metadata_compiled_valid.parquet.gzip\"))\n",
    "# loop through all samples and load\n",
    "error_files = []\n",
    "error_labels = []\n",
    "for i in tqdm(range(len(all_df))):\n",
    "    path = os.path.join(AUDIO_DIR, all_df.iloc[i, 0])+\".wav\"\n",
    "    label = all_df.iloc[i, 9]\n",
    "    try:\n",
    "        audio, sr = torchaudio.load(path)\n",
    "    except:\n",
    "        #print(f\"Error loading {path}\")\n",
    "        error_files.append(path)\n",
    "        error_labels.append(label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e26e47",
   "metadata": {},
   "source": [
    "Count how many bad wav files there are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4b97384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of bad wav files in all: 788\n",
      "Number of bad healthy samples: 475\n",
      "Number of bad covid samples: 20\n",
      "Number of bad symptomatic samples: 293\n"
     ]
    }
   ],
   "source": [
    "print('Number of bad wav files in all:', len(error_files))\n",
    "#count how many of each label\n",
    "healthy = 0\n",
    "covid = 0\n",
    "symptomatic = 0\n",
    "for label in error_labels:\n",
    "    if label == 'healthy':\n",
    "        healthy += 1\n",
    "    elif label == 'COVID-19':\n",
    "        covid += 1\n",
    "    elif label == 'symptomatic':\n",
    "        symptomatic += 1\n",
    "print('Number of bad healthy samples:', healthy)\n",
    "print('Number of bad covid samples:', covid)\n",
    "print('Number of bad symptomatic samples:', symptomatic)\n",
    "\n",
    "\n",
    "#write error_files to csv\n",
    "with open('error_files.csv', 'w') as f:\n",
    "    for item in error_files:\n",
    "        f.write(item[14:-4])\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c29e91",
   "metadata": {},
   "source": [
    "Try reconverting all the bad wav files -- found that they are all existing wav files in the folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1311c9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "\n",
    "coughvid = '../../coughvid_20211012/'\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "#read in error files in pd\n",
    "error_files = pd.read_csv('error_files.csv', header=None)\n",
    "#cut off the front and .wav at the end\n",
    "test = error_files[0].str[14:-4]\n",
    "\n",
    "count = 0\n",
    "for file in tqdm(test):\n",
    "# run ffmpeg -i \"file.webm\" -vn \"file.wav\" in terminal to convert to wav\n",
    "    print(coughvid + file + '.webm')\n",
    "    if os.path.isfile(coughvid + file + '.webm'):\n",
    "        subprocess.call([\"ffmpeg\", \"-i\", coughvid+file+\".webm\", current_dir+'./temp_wav/'+file+\".wav\"])\n",
    "    elif os.path.isfile(coughvid + file + '.ogg'):\n",
    "        subprocess.call([\"ffmpeg\", \"-i\", coughvid+file+\".ogg\", current_dir+'./temp_wav/'+file+\".wav\"])\n",
    "    else:\n",
    "        print(\"Error: No file name {0}\".format(file))\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041a8d59",
   "metadata": {},
   "source": [
    "Create the new data without the bad wav files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56606d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 788/788 [00:06<00:00, 130.51it/s]\n"
     ]
    }
   ],
   "source": [
    "all_df = pd.read_parquet(os.path.join(AUDIO_DIR, \"metadata_compiled_valid.parquet.gzip\"))\n",
    "# for each file name in error files\n",
    "# remove it from all_df\n",
    "# create new train/test split\n",
    "\n",
    "\n",
    "#read in error files in pd\n",
    "error_files = pd.read_csv('error_files.csv', header=None)\n",
    "\n",
    "#for each file name in error files\n",
    "#remove it from all_df\n",
    "# create new train/test split\n",
    "for file in tqdm(error_files[0]):\n",
    "    #if file equals uuid in all_df remove it from all_df\n",
    "    #remove row from all_df\n",
    "    all_df = all_df.drop(all_df.index[all_df['uuid'] == file])\n",
    "\n",
    "#save new all_df\n",
    "all_df.to_parquet(os.path.join(AUDIO_DIR, \"metadata_compiled_valid_edited.parquet.gzip\"))\n",
    "#save new all_df as csv\n",
    "all_df.to_csv(os.path.join(AUDIO_DIR, \"metadata_compiled_valid_edited.csv\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0659416f",
   "metadata": {},
   "source": [
    "Serena: Data Processing End\n",
    "---------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "849e78e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 646/646 [01:54<00:00,  5.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 534.3469835519791, Training accuracy : 0.7233630418777466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:11<00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validataion loss: 59.077050268650055, Validation accuracy : 0.7299651503562927\n",
      "Saved at ../models/epoch_0.pth\n",
      "---------------------------\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 646/646 [01:54<00:00,  5.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 518.97364538908, Training accuracy : 0.7477721571922302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:11<00:00,  6.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validataion loss: 57.54184144735336, Validation accuracy : 0.7517421841621399\n",
      "Saved at ../models/epoch_1.pth\n",
      "---------------------------\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 646/646 [01:57<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 517.2776116132736, Training accuracy : 0.75019371509552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:11<00:00,  6.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validataion loss: 57.03735435009003, Validation accuracy : 0.7587108016014099\n",
      "Saved at ../models/epoch_2.pth\n",
      "---------------------------\n",
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 646/646 [01:55<00:00,  5.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 516.3263672590256, Training accuracy : 0.751840353012085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:10<00:00,  6.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validataion loss: 57.12068718671799, Validation accuracy : 0.7578397393226624\n",
      "Saved at ../models/epoch_3.pth\n",
      "---------------------------\n",
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 646/646 [01:57<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 513.6064985990524, Training accuracy : 0.7561022639274597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:10<00:00,  6.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validataion loss: 56.99568712711334, Validation accuracy : 0.7595818638801575\n",
      "Saved at ../models/epoch_4.pth\n",
      "---------------------------\n",
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 646/646 [02:11<00:00,  4.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 513.4895613789558, Training accuracy : 0.7562960386276245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:12<00:00,  5.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validataion loss: 57.37068724632263, Validation accuracy : 0.7543553709983826\n",
      "Saved at ../models/epoch_5.pth\n",
      "---------------------------\n",
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 646/646 [02:00<00:00,  5.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 513.5343533754349, Training accuracy : 0.7561991214752197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:11<00:00,  6.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validataion loss: 57.360287606716156, Validation accuracy : 0.7543553709983826\n",
      "Saved at ../models/epoch_6.pth\n",
      "---------------------------\n",
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 646/646 [01:58<00:00,  5.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 514.170517206192, Training accuracy : 0.7552305459976196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:11<00:00,  6.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validataion loss: 57.31188726425171, Validation accuracy : 0.7552264928817749\n",
      "Saved at ../models/epoch_7.pth\n",
      "---------------------------\n",
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 646/646 [02:02<00:00,  5.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 514.0994479060173, Training accuracy : 0.7553274035453796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:11<00:00,  6.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validataion loss: 57.05819469690323, Validation accuracy : 0.7587108016014099\n",
      "Saved at ../models/epoch_8.pth\n",
      "---------------------------\n",
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 646/646 [01:59<00:00,  5.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 513.6010187268257, Training accuracy : 0.7561022639274597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:11<00:00,  6.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validataion loss: 57.18318724632263, Validation accuracy : 0.75696861743927\n",
      "Saved at ../models/epoch_9.pth\n",
      "---------------------------\n",
      "Finished training\n",
      "---------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(model, train_dataloader, val_dataloader, loss_fn, optimiser, device, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0be4c890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:11<00:00,  6.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation loss: 57.12068724632263, Evaluation accuracy : 0.7578397393226624\n",
      "---------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(model, test_dataloader, loss_fn, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4270da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92ad25a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "def evaluate_confusion(model, eval_data_loader, device):\n",
    "    trues = []\n",
    "    preds =[]\n",
    "    for x_batch, y_batch in tqdm(eval_data_loader):\n",
    "        with torch.no_grad():\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            # calculate loss\n",
    "            y_pred = model(x_batch)\n",
    "\n",
    "\n",
    "            trues += torch.clamp(y_batch, max=1)\n",
    "\n",
    "\n",
    "            preds += torch.clamp(torch.argmax(y_pred, axis = 1), max=1)\n",
    "            \n",
    "            \n",
    "    return np.array(trues), np.array(preds)\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "494fdd01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:12<00:00,  5.92it/s]\n"
     ]
    }
   ],
   "source": [
    "trues, preds = evaluate_confusion(model, test_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2eba3ddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x29d3af940>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cfm = confusion_matrix(trues, preds)\n",
    "#ConfusionMatrixDisplay(cfm, display_labels=['healthy', 'symptomatic', 'COVID-19']).plot()\n",
    "ConfusionMatrixDisplay(cfm, display_labels=['healthy', 'COVID-19']).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "99a40673",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cfm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [64]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcfm\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cfm' is not defined"
     ]
    }
   ],
   "source": [
    "cfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "16a9e3d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0264777",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "9f480ccb6be28d4b7a840fe3b1174df64fdfbdad14d75b02fbd7e3b419aecfda"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
