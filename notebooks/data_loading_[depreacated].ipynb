{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0286706-3f9d-4a24-86f8-2eec93a18f18",
   "metadata": {},
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0fa123a-0f7e-49a2-b007-8f221368e825",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "from segmentation import segment_cough\n",
    "import datasets\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "SAMPLE_RATE = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b500f18-423e-483e-87a1-b1cd81285332",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_folder = \"../valid_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5c7ebd6-3be6-4065-bf8e-8527d2e160fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "os.chdir(data_folder)\n",
    "sound_files =  sorted([f for f in glob.glob(\"*.wav\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "495bf593-4a2a-4d33-8f58-c6f90de912a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration ../valid_data/metadata_compiled_valid.csv-24bdde2a7bd56514\n",
      "Found cached dataset csv (/Users/nantanick/.cache/huggingface/datasets/csv/../valid_data/metadata_compiled_valid.csv-24bdde2a7bd56514/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1585b658bbb455bb0172f77fa864692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metadata = datasets.load_dataset(\"csv\", os.path.join(data_folder, \"metadata_compiled_valid.csv\"))\n",
    "metadata = metadata['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33d0ddde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "assert len(sound_files) == len(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0694ab0b-0182-4bf4-bb08-98fa88b8cfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#small version\n",
    "sound_files= sound_files[:20]\n",
    "metadata = metadata.select(range(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2c84104-787f-46ac-8003-7ccda41110c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = datasets.Dataset.from_dict(\n",
    "    {\n",
    "        \"audio_path\": sound_files,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02591e8b-abd2-46d7-a7b9-0856c68f0ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9151c0a0881c465a9221b3bc623530bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def load_audio(x):\n",
    "    tensor, sample_rate = torchaudio.load(x['audio_path'])\n",
    "    tensor = torchaudio.functional.resample(tensor, sample_rate, SAMPLE_RATE)\n",
    "    return {'audio':tensor}\n",
    "\n",
    "audio = audio.map(load_audio).with_format(\"numpy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec4c4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def segment_audio(example):\n",
    "#     \"\"\"\n",
    "#     Takes the first 3 coughs (max 1 sec)\n",
    "#     and put it in an array\n",
    "#     \"\"\"\n",
    "#     x = example['audio'][0]\n",
    "#     coughs, _ = segment_cough(x, SAMPLE_RATE)\n",
    "#     arr = coughs[0]\n",
    "#     res = np.zeros(SAMPLE_RATE)\n",
    "#     _min = min(len(arr), SAMPLE_RATE)\n",
    "#     res[:_min] = arr[:_min]\n",
    "#     return {'coughs':res}\n",
    "\n",
    "# audio = audio.map(segment_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72da474",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 16000\n",
    "NUM_SAMPLES = SAMPLE_RATE*10\n",
    "\n",
    "def _cut_if_necessary(signal):\n",
    "    if signal.shape[1] > self.num_samples:\n",
    "        signal = signal[:, :self.num_samples]\n",
    "    return signal\n",
    "\n",
    "def _right_pad_if_necessary(signal):\n",
    "    length_signal = signal.shape[1]\n",
    "    if length_signal < NUM_SAMPLES:\n",
    "        num_missing_samples = NUM_SAMPLES - length_signal\n",
    "        last_dim_padding = (0, num_missing_samples)\n",
    "        signal = torch.nn.functional.pad(signal, last_dim_padding)\n",
    "    return signal\n",
    "\n",
    "def _resample_if_necessary(signal, sr):\n",
    "    if sr != SAMPLE_RATE:\n",
    "        resampler = torchaudio.transforms.Resample(sr, SAMPLE_RATE)\n",
    "        signal = resampler(signal)\n",
    "    return signal\n",
    "\n",
    "def _mix_down_if_necessary(self, signal):\n",
    "    if signal.shape[0] > 1:\n",
    "        signal = torch.mean(signal, dim=0, keepdim=True)\n",
    "    return signal\n",
    "\n",
    "def segment_audio(example):\n",
    "    signal = example['audio']\n",
    "    signal = _resample_if_necessary(signal, sr)\n",
    "    signal = _mix_down_if_necessary(signal)\n",
    "    signal = _cut_if_necessary(signal)\n",
    "    signal = _right_pad_if_necessary(signal)\n",
    "    signal = transformation(signal)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "eebe39f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = metadata.add_column('audio', audio['audio'])\n",
    "dataset = datasets.concatenate_datasets([audio, metadata], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "de571e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 16000)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(dataset['coughs'][0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c6f69eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "keeps = ['audio', 'status', 'status_SSL']\n",
    "remove = [c for c in dataset.features if c not in keeps]\n",
    "ds_torch = dataset.remove_columns(remove).with_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "61870120",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = ds_torch['audio'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "cc8bea51",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ds_torch['coughs']\n",
    "y = ds_torch['status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85793ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyPipeline(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_fft=1024,\n",
    "        n_mel=256,\n",
    "        stretch_factor=0.8,\n",
    "        sample_rate = 16000\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.spec = Spectrogram(n_fft=n_fft, power=2)\n",
    "        self.sample_rate= sample_rate\n",
    "        \n",
    "\n",
    "#         self.spec_aug = torch.nn.Sequential(\n",
    "#             TimeStretch(stretch_factor, fixed_rate=True),\n",
    "#             FrequencyMasking(freq_mask_param=80),\n",
    "#             TimeMasking(time_mask_param=80),\n",
    "#         )\n",
    "\n",
    "        self.mel_scale = MelScale(\n",
    "            n_mels=n_mel, sample_rate=resample_freq, n_stft=n_fft // 2 + 1)\n",
    "\n",
    "    def forward(self, waveform: torch.Tensor) -> torch.Tensor:\n",
    "        \n",
    "        wavefrom = torchaudio.transforms.PitchShift(waveform, self.sample_rate) \n",
    "        # Convert to power spectrogram\n",
    "        spec = self.spec(waveform)\n",
    "\n",
    "#         # Apply SpecAugment\n",
    "#         spec = self.spec_aug(spec)\n",
    "\n",
    "        # Convert to mel-scale\n",
    "        mel = self.mel_scale(spec)\n",
    "        cv2.resize(np.array(img), (256,256)).shape\n",
    "\n",
    "        return mel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "10add66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec =  torchaudio.transforms.Spectrogram(n_fft=1024, power=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4a4c13a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.squeeze(spec(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b481a9a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.resize(np.array(img), (256,256)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "fc835b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 513, 306])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
