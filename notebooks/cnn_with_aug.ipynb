{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "72bf15ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import audiomentations\n",
    "#from audiomentations import Compose, AddGaussianNoise, PitchShift\n",
    "#import torch_audiomentations\n",
    "from torch_audiomentations import Compose, PitchShift, TimeInversion\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, '../src')\n",
    "from segmentation import segment_cough\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a6fe837a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from https://github.com/musikalkemist/pytorchforaudio\n",
    "class CoughDataset(Dataset):\n",
    "\n",
    "    def __init__(self,\n",
    "                 annotations_df,\n",
    "                 audio_dir,\n",
    "                #  transformation,\n",
    "                 target_sample_rate,\n",
    "                 num_samples,\n",
    "                 device,\n",
    "                #  segment=False,\n",
    "                #  augment=False,\n",
    "                ):\n",
    "        self.annotations = annotations_df\n",
    "        self.audio_dir = audio_dir\n",
    "        self.device = device\n",
    "        # self.transformation = transformation.to(self.device)\n",
    "        self.target_sample_rate = target_sample_rate\n",
    "        self.num_samples = num_samples\n",
    "        self.label_dict = {'healthy':0, 'symptomatic':1, 'COVID-19':2}\n",
    "        self.label_weights = self._calculate_weights(annotations_df)\n",
    "        \n",
    "        # self.do_segment = segment\n",
    "\n",
    "        # self.segmentation = segment_cough\n",
    "\n",
    "        # self.do_augment = augment\n",
    "        # self.augmentations = Compose(\n",
    "        #         [\n",
    "        #             AddGaussianNoise(min_amplitude=0.01, max_amplitude=0.05, p=0.5),\n",
    "        #             PitchShift(min_semitones=-8, max_semitones=8, p=0.5)\n",
    "        #         ]\n",
    "        # )\n",
    "        # self.augmentations = Compose(\n",
    "        #     transforms=[\n",
    "        #         PitchShift(\n",
    "        #             mode = \"per_example\",\n",
    "        #             p=0.5,\n",
    "        #             sample_rate=self.target_sample_rate\n",
    "        #             ),\n",
    "        #         TimeInversion(\n",
    "        #             mode = \"per_example\",\n",
    "        #             p=0.5,\n",
    "        #         ),\n",
    "        #     ]\n",
    "        # )\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        audio_sample_path = self._get_audio_sample_path(index)\n",
    "        label = self.label_dict[self._get_audio_sample_label(index)]\n",
    "        signal, sr = torchaudio.load(audio_sample_path)\n",
    "\n",
    "        # if self.do_segment:\n",
    "        #     segments, segment_mask = self.segmentation(signal.numpy()[0], float(sr))\n",
    "        #     #print('segment length: ', len(segments))\n",
    "        #     if len(segments) > 0:\n",
    "        #         signal = torch.tensor(segments[0])\n",
    "        #         signal = signal.unsqueeze(0)\n",
    "        #     else:\n",
    "        #         signal = signal\n",
    "        #     #print('signal in self.do_segment: ', signal)\n",
    "\n",
    "        \n",
    "        signal = signal.to(self.device)\n",
    "        signal = self._resample_if_necessary(signal, sr)\n",
    "        signal = self._mix_down_if_necessary(signal)\n",
    "        signal = self._cut_if_necessary(signal)\n",
    "        signal = self._right_pad_if_necessary(signal)\n",
    "\n",
    "        # if self.do_augment:\n",
    "        #     #signal = torch.from_numpy(self.augmentations(signal.numpy(), sr))\n",
    "        #     # print('signal shape: ', signal.shape)\n",
    "        #     # print('sample rate: ', sr)\n",
    "        #     # print('target sample rate: ', self.target_sample_rate)\n",
    "        #     # add a 1 in front of the signal array\n",
    "        #     signal = signal.unsqueeze(0)\n",
    "        #     signal = self.augmentations(signal, self.target_sample_rate)\n",
    "        #     # remove the 1 in front of the signal array\n",
    "        #     signal = signal.squeeze(0)\n",
    "        \n",
    "\n",
    "        signal = self.transformation(signal)\n",
    "\n",
    "        \n",
    "        return signal, label\n",
    "\n",
    "    def _cut_if_necessary(self, signal):\n",
    "        if signal.shape[1] > self.num_samples:\n",
    "            signal = signal[:, :self.num_samples]\n",
    "        return signal\n",
    "\n",
    "    def _right_pad_if_necessary(self, signal):\n",
    "        length_signal = signal.shape[1]\n",
    "        if length_signal < self.num_samples:\n",
    "            num_missing_samples = self.num_samples - length_signal\n",
    "            last_dim_padding = (0, num_missing_samples)\n",
    "            signal = torch.nn.functional.pad(signal, last_dim_padding)\n",
    "        return signal\n",
    "\n",
    "    def _resample_if_necessary(self, signal, sr):\n",
    "        #print('resampled signal')\n",
    "        if sr != self.target_sample_rate:\n",
    "            resampler = torchaudio.transforms.Resample(sr, self.target_sample_rate)\n",
    "            signal = resampler(signal)\n",
    "        return signal\n",
    "\n",
    "    def _mix_down_if_necessary(self, signal):\n",
    "        if signal.shape[0] > 1:\n",
    "            signal = torch.mean(signal, dim=0, keepdim=True)\n",
    "        return signal\n",
    "\n",
    "    def _get_audio_sample_path(self, index):\n",
    "        path = os.path.join(self.audio_dir, self.annotations.iloc[index, 0])+\".wav\"\n",
    "        return path\n",
    "\n",
    "    def _get_audio_sample_label(self, index):\n",
    "        return self.annotations.iloc[index, 9]\n",
    "\n",
    "    def _calculate_weights(self, annotation_df):\n",
    "        counts = annotation_df[\"status\"].value_counts()\n",
    "        total = len(annotation_df)\n",
    "        weights = (1-(counts/total))\n",
    "        weights /= weights.sum()\n",
    "        return torch.FloatTensor(weights)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d5a17a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_DIR = \"../valid_data/\"\n",
    "SAMPLE_RATE = 16000\n",
    "NUM_SAMPLES = SAMPLE_RATE*10\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "# print(f\"Using device {device}\")\n",
    "\n",
    "# train_df = pd.read_parquet(os.path.join(AUDIO_DIR, \"train.parquet.gzip\"))\n",
    "# val_df = pd.read_parquet(os.path.join(AUDIO_DIR, \"val.parquet.gzip\"))\n",
    "# test_df = pd.read_parquet(os.path.join(AUDIO_DIR, \"test.parquet.gzip\"))\n",
    "\n",
    "# train_df = pd.read_parquet(os.path.join(AUDIO_DIR, \"train_edited.parquet.gzip\"))\n",
    "# val_df = pd.read_parquet(os.path.join(AUDIO_DIR, \"val_edited.parquet.gzip\"))\n",
    "# test_df = pd.read_parquet(os.path.join(AUDIO_DIR, \"test_edited.parquet.gzip\"))\n",
    "\n",
    "train_df = pd.read_parquet(os.path.join(AUDIO_DIR, \"train_balanced.parquet.gzip\"))\n",
    "val_df = pd.read_parquet(os.path.join(AUDIO_DIR, \"val_balanced.parquet.gzip\"))\n",
    "test_df = pd.read_parquet(os.path.join(AUDIO_DIR, \"test_balanced.parquet.gzip\"))\n",
    "\n",
    "\n",
    "# print(f\"There are {len(usd)} samples in the dataset.\")\n",
    "# signal, label = usd[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c258e123",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNNetwork(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, drop_p=0.2):\n",
    "        super().__init__()\n",
    "        # 4 conv blocks / flatten / linear / softmax\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=16,\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "                padding=0\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.Dropout(p=drop_p)\n",
    "\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=16,\n",
    "                out_channels=32,\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "                padding=0\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Dropout(p=drop_p)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=32,\n",
    "                out_channels=64,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=0\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Dropout(p=drop_p)\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=64,\n",
    "                out_channels=128,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=0\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Dropout(p=drop_p)\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear = nn.Linear(31744, 3)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        #nomralization\n",
    "        std = input_data.std()\n",
    "        input_data -= input_data.mean()\n",
    "        input_data /= std\n",
    "        \n",
    "        x = self.conv1(input_data)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear(x)\n",
    "        predictions = self.softmax(logits)\n",
    "        return predictions\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2c406986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loader(train_data, batch_size):\n",
    "    train_dataloader = DataLoader(train_data, batch_size=batch_size)\n",
    "    print('train_dataloader finished: ', train_dataloader)\n",
    "    return train_dataloader\n",
    "\n",
    "def count_correct(logits, y_true):\n",
    "    y_pred = torch.argmax(logits, axis = 1)\n",
    "    return torch.sum(y_pred==y_true)\n",
    "\n",
    "def train_single_epoch(model, train_data_loader, val_data_loader, loss_fn, optimiser, device, do_augment=False):\n",
    "    total_loss = 0.0\n",
    "    correct_pred = 0.0\n",
    "    total_pred = 0\n",
    "\n",
    "    augmentations = Compose(\n",
    "            transforms=[\n",
    "                PitchShift(\n",
    "                    mode = \"per_example\",\n",
    "                    p=0.5,\n",
    "                    sample_rate=SAMPLE_RATE\n",
    "                    ),\n",
    "                TimeInversion(\n",
    "                    mode = \"per_example\",\n",
    "                    p=0.5,\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "    mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n",
    "        sample_rate=SAMPLE_RATE,\n",
    "        n_fft=1024,\n",
    "        hop_length=512,\n",
    "        n_mels=128\n",
    "    ).to(device)\n",
    "\n",
    "    for x_batch, y_batch in tqdm(train_data_loader):\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        print('x_batch: ', x_batch.shape)\n",
    "        if do_augment:\n",
    "            signal = augmentations(x_batch, SAMPLE_RATE)\n",
    "        \n",
    "        print('signal: ', signal.shape)\n",
    "\n",
    "        # convert (batch, channel, time)-waveform into (batch*channel, time)-waveform, apply the mel spectrogram transform, and then convert back.\n",
    "        signal = signal.reshape(-1, signal.shape[-1])\n",
    "        print('signal: ', signal.shape)\n",
    "        signal = mel_spectrogram(signal)\n",
    "        print('signal: ', signal.shape)\n",
    "        signal = signal.reshape(x_batch.shape[0], 1, signal.shape[-2], signal.shape[-1])\n",
    "        print('signal: ', signal.shape)\n",
    "        \n",
    "        # calculate loss\n",
    "        y_pred = model(x_batch)\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        \n",
    "        correct_pred += count_correct(y_pred, y_batch)\n",
    "        total_pred += y_batch.shape[0]\n",
    "\n",
    "        # backpropagate error and update weights\n",
    "        optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f\"Training loss: {total_loss}, Training accuracy : {correct_pred/total_pred}\")\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    correct_pred = 0.0\n",
    "    total_pred = 0\n",
    "    for x_batch, y_batch in tqdm(val_data_loader):\n",
    "        with torch.no_grad():\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            y_pred = model(x_batch)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            total_loss += loss.item() \n",
    "            \n",
    "        correct_pred += count_correct(y_pred, y_batch)\n",
    "        total_pred += y_batch.shape[0]\n",
    "        \n",
    "    print(f\"Validataion loss: {total_loss}, Validation accuracy : {correct_pred/total_pred}\")\n",
    "\n",
    "    \n",
    "def train(model, train_data_loader, val_data_loader, loss_fn, optimiser, device, epochs, do_augment):\n",
    "    for i in range(epochs):\n",
    "        print(f\"Epoch {i+1}\")\n",
    "        train_single_epoch(model, train_data_loader, val_data_loader, loss_fn, optimiser, device)\n",
    "        \n",
    "        path = os.path.join(MODEL_FOLDER, f\"epoch_{i}.pth\")\n",
    "        torch.save(model.state_dict(), path)\n",
    "        print(f\"Saved at {path}\")\n",
    "        print(\"---------------------------\")\n",
    "    print(\"Finished training\")\n",
    "    print(\"---------------------------\")\n",
    "    \n",
    "    \n",
    "def evaluate(model, eval_data_loader, loss_fn, device):\n",
    "    print(\"Evaluating model\")\n",
    "    total_loss = 0.0\n",
    "    correct_pred = 0.0\n",
    "    total_pred = 0\n",
    "    for x_batch, y_batch in tqdm(eval_data_loader):\n",
    "        with torch.no_grad():\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            # calculate loss\n",
    "            y_pred = model(x_batch)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "\n",
    "            correct_pred += count_correct(y_pred, y_batch)\n",
    "            total_pred += y_batch.shape[0]\n",
    "\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "    print(f\"Evaluation loss: {total_loss}, Evaluation accuracy : {correct_pred/total_pred}\")\n",
    "    print(\"---------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b393f0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data:  <__main__.CoughDataset object at 0x2a0e80af0>\n",
      "train_dataloader finished:  <torch.utils.data.dataloader.DataLoader object at 0x29aa73160>\n",
      "train_dataloader finished:  <torch.utils.data.dataloader.DataLoader object at 0x296bcf9a0>\n",
      "train_dataloader finished:  <torch.utils.data.dataloader.DataLoader object at 0x29aa73940>\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE =16\n",
    "EPOCHS = 50\n",
    "MODEL_FOLDER = '../models/'\n",
    "\n",
    "# mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n",
    "#     sample_rate=SAMPLE_RATE,\n",
    "#     n_fft=1024,\n",
    "#     hop_length=512,\n",
    "#     n_mels=128\n",
    "# )\n",
    "\n",
    "train_data = CoughDataset(train_df,\n",
    "                        AUDIO_DIR,\n",
    "                        # mel_spectrogram,\n",
    "                        SAMPLE_RATE,\n",
    "                        NUM_SAMPLES,\n",
    "                        device,\n",
    "                        # augment = True\n",
    "                        )\n",
    "print('train data: ', train_data)\n",
    "\n",
    "val_data = CoughDataset(val_df,\n",
    "                        AUDIO_DIR,\n",
    "                        # mel_spectrogram,\n",
    "                        SAMPLE_RATE,\n",
    "                        NUM_SAMPLES,\n",
    "                        device)\n",
    "\n",
    "test_data = CoughDataset(test_df,\n",
    "                        AUDIO_DIR,\n",
    "                        # mel_spectrogram,\n",
    "                        SAMPLE_RATE,\n",
    "                        NUM_SAMPLES,\n",
    "                        device)\n",
    "\n",
    "train_dataloader = create_data_loader(train_data, BATCH_SIZE)\n",
    "val_dataloader = create_data_loader(val_data, BATCH_SIZE)\n",
    "test_dataloader = create_data_loader(val_data, BATCH_SIZE)\n",
    "\n",
    "# construct model and assign it to device\n",
    "model = CNNNetwork().to(device)\n",
    "\n",
    "# initialise loss funtion + optimiser\n",
    "#loss_fn = nn.CrossEntropyLoss(weight=train_data.label_weights)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimiser = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "849e78e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "train() got an unexpected keyword argument 'do_augment'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train(model, train_dataloader, val_dataloader, loss_fn, optimiser, device, EPOCHS, do_augment\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: train() got an unexpected keyword argument 'do_augment'"
     ]
    }
   ],
   "source": [
    "train(model, train_dataloader, val_dataloader, loss_fn, optimiser, device, EPOCHS, do_augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0be4c890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  7.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation loss: 9.924549341201782, Evaluation accuracy : 0.5686274766921997\n",
      "---------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(model, test_dataloader, loss_fn, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c4270da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "92ad25a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "def evaluate_confusion(model, eval_data_loader, device):\n",
    "    trues = []\n",
    "    preds =[]\n",
    "    for x_batch, y_batch in tqdm(eval_data_loader):\n",
    "        with torch.no_grad():\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            # calculate loss\n",
    "            y_pred = model(x_batch)\n",
    "\n",
    "\n",
    "            trues += torch.clamp(y_batch, max=1)\n",
    "\n",
    "\n",
    "            preds += torch.clamp(torch.argmax(y_pred, axis = 1), max=1)\n",
    "            \n",
    "            \n",
    "    return np.array(trues), np.array(preds)\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "494fdd01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  7.67it/s]\n"
     ]
    }
   ],
   "source": [
    "trues, preds = evaluate_confusion(model, test_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2eba3ddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x2ad2866e0>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGwCAYAAACKOz5MAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAABDkElEQVR4nO3dd3hUZdrH8d8ESCGNIiQEQgBJCL0qREWKkYhrACmKooIUFw1dbK+LdFEUYdEAihDAFRERWIqgMQqoFAUNawkt0knCrpQQJIXMef/IMusYwJnMhAzH7+e6zqVzyvPcwxXM7f2UYzEMwxAAAIAH8yrrAAAAAP4ICQsAAPB4JCwAAMDjkbAAAACPR8ICAAA8HgkLAADweCQsAADA45Uv6wDgGKvVqhMnTigwMFAWi6WswwEAOMEwDJ07d05hYWHy8iq9WkFubq7y8/Ndbsfb21u+vr5uiMh9SFiuEydOnFB4eHhZhwEAcMHRo0dVq1atUmk7NzdXdSMClHmy0OW2QkNDdfDgQY9KWkhYrhOBgYGSpMPf1lFQACN5MKdezdqUdQhAqbhoFGhL3irbf8tLQ35+vjJPFurwrjoKCiz574nsc1ZFtD6k/Px8EhY479IwUFCAl0s/iIAnK2/xLusQgFJ1LYb0AwItCggseT9Weea0AxIWAABMpNCwqtCFtwQWGlb3BeNGJCwAAJiIVYasKnnG4sqzpYmxBQAA4PGosAAAYCJWWeXKoI5rT5ceEhYAAEyk0DBUaJR8WMeVZ0sTQ0IAAMDjUWEBAMBEzDrploQFAAATscpQoQkTFoaEAACAx6PCAgCAiTAkBAAAPB6rhAAAAMoIFRYAAEzE+t/Dlec9EQkLAAAmUujiKiFXni1NJCwAAJhIoSEX39bsvljciTksAADA41FhAQDARJjDAgAAPJ5VFhXK4tLznoghIQAA4PGosAAAYCJWo+hw5XlPRIUFAAATKfzvkJArh1P9FRZq3Lhxqlu3rvz8/HTjjTdq8uTJMn6zY65hGHrhhRdUo0YN+fn5KTY2Vvv373eqHxIWAABQYi+//LLmzp2rN954Q2lpaXr55Zc1ffp0vf7667Z7pk+frtmzZ2vevHnasWOH/P39FRcXp9zcXIf7YUgIAAATKUmV5PfPO2Pr1q3q3r27/vKXv0iS6tSpo/fee09ff/21pKLqyqxZs/S3v/1N3bt3lyQtWbJEISEhWr16tfr27etQP1RYAAAwEathcfmQpOzsbLsjLy/vsv3dcsstSklJ0b59+yRJu3fv1pdffqmuXbtKkg4ePKjMzEzFxsbangkODlbbtm21bds2h78XFRYAAFBMeHi43efx48drwoQJxe579tlnlZ2drejoaJUrV06FhYWaOnWq+vXrJ0nKzMyUJIWEhNg9FxISYrvmCBIWAABMxF1DQkePHlVQUJDtvI+Pz2XvX758ud59910tXbpUjRs3VmpqqkaNGqWwsDD179+/xHH8HgkLAAAmUigvFbow46Pwv/8MCgqyS1iu5KmnntKzzz5rm4vStGlTHT58WNOmTVP//v0VGhoqScrKylKNGjVsz2VlZalFixYOx8UcFgAATMRwcf6KYThXnfn111/l5WWfTpQrV05Wa9Em/3Xr1lVoaKhSUlJs17Ozs7Vjxw7FxMQ43A8VFgAAUGLx8fGaOnWqateurcaNG+u7777Ta6+9poEDB0qSLBaLRo0apSlTpigyMlJ169bVuHHjFBYWph49ejjcDwkLAAAmcq2XNb/++usaN26cnnjiCZ08eVJhYWH661//qhdeeMF2z9NPP63z58/rscce05kzZ3Tbbbdp48aN8vX1dbgfi/HbrejgsbKzsxUcHKzT++opKJCRPJhT13rtyjoEoFRcNPL1We5ynT171qF5ISVx6ffEhn/Vlb8LvyfOn7Oqa7ODpRprSfCbDwAAeDyGhAAAMBGrLLK6UI+wyjMHXkhYAAAwkWs9h+VaYUgIAAB4PCosAACYSKHhpULDhY3jPHQtDgkLAAAmUjSHpeTDOq48W5oYEgIAAB6PCgsAACZidfFdQqwSAgAApY45LAAAwONZ5WXKfViYwwIAADweFRYAAEyk0LCo0HBh4zgXni1NJCwAAJhIoYuTbgsZEgIAACgZKiwAAJiI1fCS1YVVQlZWCQEAgNLGkBAAAEAZocICAICJWOXaSh+r+0JxKxIWAABMxPWN4zxz8MUzowIAAPgNKiwAAJiI6+8S8sxaBgkLAAAmYpVFVrkyh4WdbgEAQCkza4XFM6MCAAD4DSosAACYiOsbx3lmLYOEBQAAE7EaFlld2YfFQ9/W7JlpFAAAwG9QYQEAwESsLg4JeerGcSQsAACYiOtva/bMhMUzowIAAPgNKiwAAJhIoSwqdGHzN1eeLU0kLAAAmAhDQgAAAGWEhAUAABMp1P+GhUp2OKdOnTqyWCzFjoSEBElSbm6uEhISVLVqVQUEBKhXr17Kyspy+nuRsAAAYCKXhoRcOZzxzTffKCMjw3YkJydLkvr06SNJGj16tNauXasPPvhAmzdv1okTJ9SzZ0+nvxdzWAAAMJFr/fLDatWq2X1+6aWXdOONN6pDhw46e/asFixYoKVLl6pz586SpKSkJDVs2FDbt29Xu3btHO6HCgsAACgmOzvb7sjLy/vDZ/Lz8/WPf/xDAwcOlMVi0a5du1RQUKDY2FjbPdHR0apdu7a2bdvmVDwkLAAAmIghi6wuHMZ/lzWHh4crODjYdkybNu0P+169erXOnDmjAQMGSJIyMzPl7e2tSpUq2d0XEhKizMxMp74XQ0IAAJiIu4aEjh49qqCgINt5Hx+fP3x2wYIF6tq1q8LCwkrc/5WQsAAAgGKCgoLsEpY/cvjwYX366adauXKl7VxoaKjy8/N15swZuypLVlaWQkNDnYqHISEAAEzEalhcPkoiKSlJ1atX11/+8hfbudatW6tChQpKSUmxndu7d6+OHDmimJgYp9qnwgIAgIkUuvi25pI8a7ValZSUpP79+6t8+f+lFsHBwRo0aJDGjBmjKlWqKCgoSMOHD1dMTIxTK4QkEhYAAOCiTz/9VEeOHNHAgQOLXZs5c6a8vLzUq1cv5eXlKS4uTnPmzHG6DxIWAABMxJVhnUvPO6tLly4yDOOy13x9fZWYmKjExMQSxySRsAAAYCpWecnqwpCQK8+WJs+MCgAA4DeosAAAYCKFhkWFLgwJufJsaSJhAQDARMpiDsu1QMICAICJGCV44/Lvn/dEnhkVAADAb1BhAQDARAplUaFcmMPiwrOliYQFAAATsRquzUOxXn47lTLHkBAAAPB4JCz40yoslBZPD9UjbRsqvl4zDYhpqHdnhuj3mzUe2e+j8f3r6t4GTdXtxqYa3jVKJ49VKJugATfqM/SENvy8Q38dd7isQ4EbWf876daVwxN5ZlQO6Nixo0aNGlWqfdSpU0ezZs266j0TJkxQixYtSjUOlI7lidW1bvENSph6XPM379Gg50/ogznV9c8FN9juOXHIW2N6RCq8fq5eWXFA81L26sFRmfL29dCaKeCgqGY5uvuBk/o5rWJZhwI3s8ri8uGJrtuEpSxYLBatXr26rMOAm/y0018xcWfVNjZboeH5an/PWbXqcE57U//3H/BFL9XQzZ2zNXhchuo3vaCwOvmKictWpRsulmHkgGt8KxbqqZnp+vv/1VXO2XJlHQ7gEBIW/Gk1anNeqV8G6li6jyQp/Udf/fi1v27qfE6SZLVKX6cEqWa9PP3fA/V0X9PGGvGXSG3dEFyWYQMuS5h4SN98XkmpX/GzbEaXdrp15fBE13XCYrVa9fTTT6tKlSoKDQ3VhAkTbNfOnDmjwYMHq1q1agoKClLnzp21e/du2/X09HR1795dISEhCggI0E033aRPP/30in3VqVNHknTvvffKYrHYPl/yzjvvqE6dOgoODlbfvn117lzRL70lS5aoatWqysvLs7u/R48eevjhh137A4BL7h92Uh26n9bg26N1d+3mSujSQPcO+bc69zwtSTrzn/K6cL6c3n+jutp0Oqdp7/2sW+86q0mD6+hf2/zLOHqgZDrc84tubHJeSdPDyzoUlBLmsHigxYsXy9/fXzt27ND06dM1adIkJScnS5L69OmjkydPasOGDdq1a5datWqlO+64Q6dOnZIk5eTk6O6771ZKSoq+++473XXXXYqPj9eRI0cu29c333wjSUpKSlJGRobts1SU/KxevVrr1q3TunXrtHnzZr300ku2OAoLC7VmzRrb/SdPntT69es1cODAK363vLw8ZWdn2x1wry1rKumzlZX1bOJhJX68V2P/fkQr5lVX8vLKkiTDWnRfTFy2ej72b93Y5ILuH35SbWOztX7JDVdpGfBMN9TI019fOKTpo+urIP+6/s8//oSu631YmjVrpvHjx0uSIiMj9cYbbyglJUV+fn76+uuvdfLkSfn4FJX7X331Va1evVorVqzQY489pubNm6t58+a2tiZPnqxVq1ZpzZo1GjZsWLG+qlWrJkmqVKmSQkND7a5ZrVYtWrRIgYGBkqSHH35YKSkpmjp1qvz8/PTggw8qKSlJffr0kST94x//UO3atdWxY8crfrdp06Zp4sSJJf/DwR+aPzlM9w87qY49zkiS6jbM1clj3lr2eojuvO+0gqoUqlx5QxFRuXbPhUfm6sevqbDg+hPZ5Lwq33BRb6z53nauXHmpyc3nFP9wprpF3yyr1TOHA+A4q1x8l5CHTrq97hOW36pRo4ZOnjyp3bt3KycnR1WrVrW7fuHCBaWnp0sqqrBMmDBB69evV0ZGhi5evKgLFy5cscJyNXXq1LElK7+N45IhQ4bopptu0vHjx1WzZk0tWrRIAwYMkMVy5R+K5557TmPGjLF9zs7OVng4JVx3ysv1ksXLfrWPVznDtqy5grehqOa/2ua4XHL8Zx9Vr1VwrcIE3CZ1a7CG3tXU7tyY6T/raLqvPngzjGTFJAwXV/oYJCzuV6GC/V4YFotFVqtVOTk5qlGjhjZt2lTsmUqVKkmSxo4dq+TkZL366quqX7++/Pz81Lt3b+Xn57stjktatmyp5s2ba8mSJerSpYt+/PFHrV+//qpt+vj42KpDKB3t7szWstkhql6zQBENcpX+g59WvlldXfr+YrunzxMn9eLQCDVpl6Pmt+Ro5+dB2p4crFdWHCjDyIGSuXC+nA7vs1/GnPurl86dqVDsPK5fvK35OtKqVStlZmaqfPnyxSbHXvLVV19pwIABuvfeeyUVVVwOHTp01XYrVKigwsLCEsU0ePBgzZo1S8ePH1dsbCzVEg/wxJRjWjy9ht54rpbO/FJeVUMKdPfD/1G/0Vm2e27telYjXjqmZW+EaO64WqpVL0/j5h9Uk7bnyzByAPjzMWXCEhsbq5iYGPXo0UPTp09XVFSUTpw4ofXr1+vee+9VmzZtFBkZqZUrVyo+Pl4Wi0Xjxo2zq4pcTp06dZSSkqJbb71VPj4+qly5ssMxPfjggxo7dqzmz5+vJUuWuPoV4QYVA6x6fNJxPT7p+FXvi3vglOIeOHWNogKurWcebFTWIcDNXF3pwyqha8hiseijjz7S7bffrkcffVRRUVHq27evDh8+rJCQEEnSa6+9psqVK+uWW25RfHy84uLi1KpVq6u2O2PGDCUnJys8PFwtW7Z0Kqbg4GD16tVLAQEB6tGjR0m/GgAAV3VpSMiVwxNZDOP3b05BabnjjjvUuHFjzZ492+lns7OzFRwcrNP76iko0JR5JqCu9dqVdQhAqbho5Ouz3OU6e/asgoKCSqWPS78nun8yUBX8vUvcTsH5fP2zy8JSjbUkTDkk5GlOnz6tTZs2adOmTZozZ05ZhwMAMDFX3wfEsuY/sZYtW+r06dN6+eWX1aBBg7IOBwBgYqwSQon90eojAABwdSQsAACYCBUWAADg8cyasLDcBAAAeDwqLAAAmIhZKywkLAAAmIgh15Yme+rmbCQsAACYiFkrLMxhAQAAHo8KCwAAJkKFBQAAeLyyePnh8ePH9dBDD6lq1ary8/NT06ZNtXPnTtt1wzD0wgsvqEaNGvLz81NsbKz279/vVB8kLAAAoMROnz6tW2+9VRUqVNCGDRv0008/acaMGapcubLtnunTp2v27NmaN2+eduzYIX9/f8XFxSk3N9fhfhgSAgDARK71kNDLL7+s8PBwJSUl2c7VrVvX9u+GYWjWrFn629/+pu7du0uSlixZopCQEK1evVp9+/Z1qB8qLAAAmIhhWFw+JCk7O9vuyMvLu2x/a9asUZs2bdSnTx9Vr15dLVu21Pz5823XDx48qMzMTMXGxtrOBQcHq23bttq2bZvD34uEBQAAFBMeHq7g4GDbMW3atMve9/PPP2vu3LmKjIzUxx9/rMcff1wjRozQ4sWLJUmZmZmSpJCQELvnQkJCbNccwZAQAAAmYpXFpY3jLj179OhRBQUF2c77+Phc/n6rVW3atNGLL74oSWrZsqV++OEHzZs3T/379y9xHL9HhQUAABNx1yqhoKAgu+NKCUuNGjXUqFEju3MNGzbUkSNHJEmhoaGSpKysLLt7srKybNccQcICAABK7NZbb9XevXvtzu3bt08RERGSiibghoaGKiUlxXY9OztbO3bsUExMjMP9MCQEAICJ/HbibEmfd8bo0aN1yy236MUXX9R9992nr7/+Wm+99ZbeeustSZLFYtGoUaM0ZcoURUZGqm7duho3bpzCwsLUo0cPh/shYQEAwESu9bLmm266SatWrdJzzz2nSZMmqW7dupo1a5b69etnu+fpp5/W+fPn9dhjj+nMmTO67bbbtHHjRvn6+jrcDwkLAAAmcq0rLJJ0zz336J577rnidYvFokmTJmnSpEkljos5LAAAwONRYQEAwEQMF4eEXKnOlCYSFgAATMSQZBiuPe+JGBICAAAejwoLAAAmYpVFFjfsdOtpSFgAADCRslgldC0wJAQAADweFRYAAEzEalhkuYYbx10rJCwAAJiIYbi4SshDlwkxJAQAADweFRYAAEzErJNuSVgAADAREhYAAODxzDrpljksAADA41FhAQDARMy6SoiEBQAAEylKWFyZw+LGYNyIISEAAODxqLAAAGAirBICAAAez/jv4crznoghIQAA4PGosAAAYCIMCQEAAM9n0jEhEhYAAMzExQqLPLTCwhwWAADg8aiwAABgIux0CwAAPJ5ZJ90yJAQAADweFRYAAMzEsLg2cdZDKywkLAAAmIhZ57AwJAQAADweFRYAAMyEjeMAAICnM+sqIYcSljVr1jjcYLdu3UocDAAAwOU4lLD06NHDocYsFosKCwtdiQcAALjqGg7rTJgwQRMnTrQ716BBA+3Zs0eSlJubqyeffFLLli1TXl6e4uLiNGfOHIWEhDjVj0MJi9VqdapRAABQNspiSKhx48b69NNPbZ/Ll/9fejF69GitX79eH3zwgYKDgzVs2DD17NlTX331lVN9uDSHJTc3V76+vq40AQAA3KkMJt2WL19eoaGhxc6fPXtWCxYs0NKlS9W5c2dJUlJSkho2bKjt27erXbt2Dvfh9LLmwsJCTZ48WTVr1lRAQIB+/vlnSdK4ceO0YMECZ5sDAAAeKDs72+7Iy8u74r379+9XWFiY6tWrp379+unIkSOSpF27dqmgoECxsbG2e6Ojo1W7dm1t27bNqXicTlimTp2qRYsWafr06fL29radb9Kkid5++21nmwMAAG5lccMhhYeHKzg42HZMmzbtsr21bdtWixYt0saNGzV37lwdPHhQ7du317lz55SZmSlvb29VqlTJ7pmQkBBlZmY69a2cHhJasmSJ3nrrLd1xxx0aOnSo7Xzz5s1tE2wAAEAZcdOQ0NGjRxUUFGQ77ePjc9nbu3btavv3Zs2aqW3btoqIiNDy5cvl5+fnQiD2nK6wHD9+XPXr1y923mq1qqCgwC1BAQCAshUUFGR3XClh+b1KlSopKipKBw4cUGhoqPLz83XmzBm7e7Kysi475+VqnE5YGjVqpC+++KLY+RUrVqhly5bONgcAANzJcMPhgpycHKWnp6tGjRpq3bq1KlSooJSUFNv1vXv36siRI4qJiXGqXaeHhF544QX1799fx48fl9Vq1cqVK7V3714tWbJE69atc7Y5AADgTtf4bc1jx45VfHy8IiIidOLECY0fP17lypXTAw88oODgYA0aNEhjxoxRlSpVFBQUpOHDhysmJsapFUJSCRKW7t27a+3atZo0aZL8/f31wgsvqFWrVlq7dq3uvPNOZ5sDAADXsWPHjumBBx7QL7/8omrVqum2227T9u3bVa1aNUnSzJkz5eXlpV69etltHOesEu3D0r59eyUnJ5fkUQAAUIoMo+hw5XlnLFu27KrXfX19lZiYqMTExJIHJRc2jtu5c6fS0tIkFc1rad26tUuBAAAAN+BtzUUulX6++uor27rqM2fO6JZbbtGyZctUq1Ytd8cIAAD+5JxeJTR48GAVFBQoLS1Np06d0qlTp5SWliar1arBgweXRowAAMBRlybdunJ4IKcrLJs3b9bWrVvVoEED27kGDRro9ddfV/v27d0aHAAAcI7FKDpced4TOZ2whIeHX3aDuMLCQoWFhbklKAAAUEImncPi9JDQK6+8ouHDh2vnzp22czt37tTIkSP16quvujU4AAAAycEKS+XKlWWx/G9M6/z582rbtq3Kly96/OLFiypfvrwGDhyoHj16lEqgAADAAdd447hrxaGEZdasWaUcBgAAcAuTDgk5lLD079+/tOMAAAC4ohJvHCdJubm5ys/Ptzv321dRAwCAa8ykFRanJ92eP39ew4YNU/Xq1eXv76/KlSvbHQAAoAyV8duaS4vTCcvTTz+tzz77THPnzpWPj4/efvttTZw4UWFhYVqyZElpxAgAAP7knB4SWrt2rZYsWaKOHTvq0UcfVfv27VW/fn1FRETo3XffVb9+/UojTgAA4AiTrhJyusJy6tQp1atXT1LRfJVTp05Jkm677TZt2bLFvdEBAACnXNrp1pXDEzmdsNSrV08HDx6UJEVHR2v58uWSiiovl16GCAAA4E5OJyyPPvqodu/eLUl69tlnlZiYKF9fX40ePVpPPfWU2wMEAABOMOmkW6fnsIwePdr277GxsdqzZ4927dql+vXrq1mzZm4NDgAAQHJxHxZJioiIUEREhDtiAQAALrLIxbc1uy0S93IoYZk9e7bDDY4YMaLEwQAAAFyOQwnLzJkzHWrMYrGQsJSye/fGqby/T1mHAZSO3GNlHQFQKqxGwbXrzKTLmh1KWC6tCgIAAB6OrfkBAADKhsuTbgEAgAcxaYWFhAUAABNxdbda0+x0CwAAcK1RYQEAwExMOiRUogrLF198oYceekgxMTE6fvy4JOmdd97Rl19+6dbgAACAk0y6Nb/TCcuHH36ouLg4+fn56bvvvlNeXp4k6ezZs3rxxRfdHiAAAIDTCcuUKVM0b948zZ8/XxUqVLCdv/XWW/Xtt9+6NTgAAOCcS5NuXTk8kdNzWPbu3avbb7+92Png4GCdOXPGHTEBAICSMulOt05XWEJDQ3XgwIFi57/88kvVq1fPLUEBAIASYg5LkSFDhmjkyJHasWOHLBaLTpw4oXfffVdjx47V448/XhoxAgCAPzmnh4SeffZZWa1W3XHHHfr11191++23y8fHR2PHjtXw4cNLI0YAAOAgNo77L4vFoueff16nTp3SDz/8oO3bt+vf//63Jk+eXBrxAQAAZ5TxkNBLL70ki8WiUaNG2c7l5uYqISFBVatWVUBAgHr16qWsrCyn2i3xTrfe3t5q1KiRbr75ZgUEBJS0GQAAYBLffPON3nzzTTVr1szu/OjRo7V27Vp98MEH2rx5s06cOKGePXs61bbTQ0KdOnWSxXLlGcSfffaZs00CAAB3cXVpcgmfzcnJUb9+/TR//nxNmTLFdv7s2bNasGCBli5dqs6dO0uSkpKS1LBhQ23fvl3t2rVzqH2nKywtWrRQ8+bNbUejRo2Un5+vb7/9Vk2bNnW2OQAA4E5uGhLKzs62Oy5tFHslCQkJ+stf/qLY2Fi787t27VJBQYHd+ejoaNWuXVvbtm1z+Gs5XWGZOXPmZc9PmDBBOTk5zjYHAAA8UHh4uN3n8ePHa8KECZe9d9myZfr222/1zTffFLuWmZkpb29vVapUye58SEiIMjMzHY7HbS8/fOihh3TzzTfr1VdfdVeTAADAWW56+eHRo0cVFBRkO+3j43PZ248ePaqRI0cqOTlZvr6+LnR8dSWedPt727ZtK9VAAQDAH3PX1vxBQUF2x5USll27dunkyZNq1aqVypcvr/Lly2vz5s2aPXu2ypcvr5CQEOXn5xfbDT8rK0uhoaEOfy+nKyy/n9VrGIYyMjK0c+dOjRs3ztnmAADAdeyOO+7Q999/b3fu0UcfVXR0tJ555hmFh4erQoUKSklJUa9evSQVvebnyJEjiomJcbgfpxOW4OBgu89eXl5q0KCBJk2apC5dujjbHAAAuI4FBgaqSZMmduf8/f1VtWpV2/lBgwZpzJgxqlKlioKCgjR8+HDFxMQ4vEJIcjJhKSws1KOPPqqmTZuqcuXKzjwKAACuBTfNYXGnmTNnysvLS7169VJeXp7i4uI0Z84cp9pwKmEpV66cunTporS0NBIWAAA8kCdszb9p0ya7z76+vkpMTFRiYmKJ23R60m2TJk30888/l7hDAAAAZzmdsEyZMkVjx47VunXrlJGRUWxjGQAAUMbK6D1CpcnhIaFJkybpySef1N133y1J6tatm90W/YZhyGKxqLCw0P1RAgAAx3jgHBZ3cDhhmThxooYOHarPP/+8NOMBAAAoxuGExTCKUq4OHTqUWjAAAMA1njDptjQ4tUroam9pBgAAHuDPPiQkSVFRUX+YtJw6dcqlgAAAAH7PqYRl4sSJxXa6BQAAnoMhIUl9+/ZV9erVSysWAADgKpMOCTm8DwvzVwAAQFlxepUQAADwYCatsDicsFit1tKMAwAAuAFzWAAAgOczaYXF6XcJAQAAXGtUWAAAMBOTVlhIWAAAMBGzzmFhSAgAAHg8KiwAAJgJQ0IAAMDTMSQEAABQRqiwAABgJgwJAQAAj2fShIUhIQAA4PGosAAAYCKW/x6uPO+JSFgAADATkw4JkbAAAGAiLGsGAAAoI1RYAAAwE4aEAADAdcFDkw5XMCQEAAA8HhUWAABMxKyTbklYAAAwE5POYWFICAAAeDwSFgAATOTSkJArhzPmzp2rZs2aKSgoSEFBQYqJidGGDRts13Nzc5WQkKCqVasqICBAvXr1UlZWltPfi4QFAAAzMdxwOKFWrVp66aWXtGvXLu3cuVOdO3dW9+7d9eOPP0qSRo8erbVr1+qDDz7Q5s2bdeLECfXs2dPpr8UcFgAAUGLx8fF2n6dOnaq5c+dq+/btqlWrlhYsWKClS5eqc+fOkqSkpCQ1bNhQ27dvV7t27RzuhwoLAAAm4q4hoezsbLsjLy/vD/suLCzUsmXLdP78ecXExGjXrl0qKChQbGys7Z7o6GjVrl1b27Ztc+p7kbAAAGAmbhoSCg8PV3BwsO2YNm3aFbv8/vvvFRAQIB8fHw0dOlSrVq1So0aNlJmZKW9vb1WqVMnu/pCQEGVmZjr1tRgSAgDATNy0rPno0aMKCgqynfbx8bniIw0aNFBqaqrOnj2rFStWqH///tq8ebMLQRRHwgIAAIq5tOrHEd7e3qpfv74kqXXr1vrmm2/097//Xffff7/y8/N15swZuypLVlaWQkNDnYqHISEAAEzkWi9rvhyr1aq8vDy1bt1aFSpUUEpKiu3a3r17deTIEcXExDjVJhUWAADM5BrvdPvcc8+pa9euql27ts6dO6elS5dq06ZN+vjjjxUcHKxBgwZpzJgxqlKlioKCgjR8+HDFxMQ4tUJIImEBAAAuOHnypB555BFlZGQoODhYzZo108cff6w777xTkjRz5kx5eXmpV69eysvLU1xcnObMmeN0PyQsAACYiMUwZDFKXmJx9tkFCxZc9bqvr68SExOVmJhY4pgkEhYAAMyFlx8CAACUDSosAACYiKsrfdyxSqg0kLAAAGAmDAkBAACUDSosAACYCENCAADA85l0SIiEBQAAEzFrhYU5LAAAwONRYQEAwEwYEgIAANcDTx3WcQVDQgAAwONRYQEAwEwMo+hw5XkPRMICAICJsEoIAACgjFBhAQDATFglBAAAPJ3FWnS48rwnYkgIAAB4PCos+HP7d6E0/6z0da6UZ5VqlpeeqiI18C66/sUFaW2OtK9AOmeV3qwu1fcu25iBErp/WJZuvfuswuvnKT/XSz/trKgFU2voWLpvWYcGd2JICDCZc1Zp5EmphY/00g1SsJd0/KIU+JvCY65VauIjdagovXa67GIF3KBZzHmtXXSD9qVWVLnyhgY8m6EX3/tZQzo0UN6FcmUdHtyEVUKlJDMzU8OHD1e9evXk4+Oj8PBwxcfHKyUlxXbP1q1bdffdd6ty5cry9fVV06ZN9dprr6mwsFCS9OGHH6pcuXI6fvz4ZfuIjIzUmDFjJEkdO3bUqFGjbNc6duwoi8Uii8UiHx8f1axZU/Hx8Vq5cqVD8Y8YMUKtW7eWj4+PWrRocdl7li9frhYtWqhixYqKiIjQK6+84lDbKGXLzknVyklPV5GivaUa5aU2vlLYb/L4O/2lR4Kk1j5lFyfgJs/3q6fk5VV0eJ+vfv7JTzNG1VZIrQJFNrtQ1qHBnS7tw+LK4YHKNGE5dOiQWrdurc8++0yvvPKKvv/+e23cuFGdOnVSQkKCJGnVqlXq0KGDatWqpc8//1x79uzRyJEjNWXKFPXt21eGYahbt26qWrWqFi9eXKyPLVu26MCBAxo0aNAV4xgyZIgyMjKUnp6uDz/8UI0aNVLfvn312GOPOfQ9Bg4cqPvvv/+y1zZs2KB+/fpp6NCh+uGHHzRnzhzNnDlTb7zxhkNtoxRtvVA09DPxF6nXCemvWdL6nLKOCrhm/IOK/qfv3BmqK/B8ZTok9MQTT8hisejrr7+Wv7+/7Xzjxo01cOBAnT9/XkOGDFG3bt301ltv2a4PHjxYISEh6tatm5YvX677779fDz/8sBYtWqT/+7//s+tj4cKFatu2rRo3bnzFOCpWrKjQ0FBJUq1atdSuXTtFR0dr4MCBuu+++xQbG3vFZ2fPni1J+ve//61//etfxa6/88476tGjh4YOHSpJqlevnp577jm9/PLLSkhIkMViuWy7eXl5ysvLs33Ozs6+YgwooYyL0pocqXeg9GCgtDdfeuOMVN4ixfn/4ePA9cxiMTR04nH98HVFHd7rV9bhwI0YEnKzU6dOaePGjUpISLBLVi6pVKmSPvnkE/3yyy8aO3Zssevx8fGKiorSe++9J0kaNGiQ9u/fry1bttjuycnJ0YoVK65aXbmS/v37q3Llyg4PDV1JXl6efH3tJ7T5+fnp2LFjOnz48BWfmzZtmoKDg21HeHi4S3HgMgxJkd7S4OCif94TIP0lQFp7vqwjA0rdsBePKyI6V9MejyjrUOBuhhsOD1RmCcuBAwdkGIaio6OveM++ffskSQ0bNrzs9ejoaNs9jRo1Urt27bRw4ULb9eXLl8swDPXt29fp+Ly8vBQVFaVDhw45/exvxcXFaeXKlUpJSZHVatW+ffs0Y8YMSVJGRsYVn3vuued09uxZ23H06FGX4sBlVCknRfyuyFi7vHTyYtnEA1wjCVOPqe2d2Xq69436Twar3nB9KLOExXBiUo+j9w4cOFArVqzQuXPnJBUNB/Xp00eBgYEljvHSkE3Xrl0VEBCggICAqw4v/d6QIUM0bNgw3XPPPfL29la7du1sCZSX15X/+H18fBQUFGR3wM2aeEtHf5ecHLsohbB4DmZlKGHqMd1y11k93edGZR1lMrkZXRoScuXwRGWWsERGRspisWjPnj1XvCcqKkqSlJaWdtnraWlptnsk2RKB5cuXa//+/frqq69KNBwkSYWFhdq/f7/q1q0rSXr77beVmpqq1NRUffTRRw63Y7FY9PLLLysnJ0eHDx9WZmambr75ZklF81lQhnoFSmn50rvZRcuZU36V1p+Xugf8755sq3QgXzpcUPT56MWiz6cKyyZmwAXDXjyuzj1P66WECF3I8VLlagWqXK1A3r4eurUpSsakq4TK7H8lq1Spori4OCUmJmrEiBHF5rGcOXNGXbp0UZUqVTRjxgzdcsstdtfXrFmj/fv3a/LkybZzgYGB6tOnjxYuXKj09HRFRUWpffv2JYpv8eLFOn36tHr16iVJqlmzZonauaRcuXK2Nt577z3FxMSoWrVqLrUJF0V7SxOrSgvOSu9kFy1rfiJYiq34v3u2XpBe+c3+K1NOFf3zkUCpf/C1jRdwUfyAXyRJr65Mtzv/6qhwJS+vUhYhAQ4r09p3YmKibr31Vt18882aNGmSmjVrposXLyo5OVlz585VWlqa3nzzTdsS42HDhikoKEgpKSl66qmn1Lt3b9133312bQ4aNEjt27dXWlqannnmGYfi+PXXX5WZmamLFy/q2LFjWrVqlWbOnKnHH39cnTp1uuqzBw4cUE5OjjIzM3XhwgWlpqZKKppT4+3trf/85z9asWKFOnbsqNzcXCUlJemDDz7Q5s2bS/RnBjeL8Ss6ruQu/6IDMIG4sOZlHQKuAbOuEirThKVevXr69ttvNXXqVD355JPKyMhQtWrV1Lp1a82dO1eS1Lt3b33++eeaOnWq2rdvr9zcXEVGRur555/XqFGjii0Lvu2229SgQQMdOHBAjzzyiENxzJ8/X/Pnz5e3t7eqVq2q1q1b6/3339e99977h88OHjzYLvlo2bKlJOngwYOqU6eOpKJqzdixY2UYhmJiYrRp0ybbsBAAAG5l0q35LYYzs19RZrKzsxUcHKyOax9XeX8mysGk7jhW1hEApeKiUaBN+qfOnj1baosoLv2eiLlrkspXKPn7oS4W5GrbxhdKNdaSYDkEAAAmwpAQAADwfFaj6HDleQ9U5i8/BAAAbnSNd7qdNm2abrrpJgUGBqp69erq0aOH9u7da3dPbm6uEhISVLVqVQUEBKhXr17Kyspyqh8SFgAAUGKbN29WQkKCtm/fruTkZBUUFKhLly46f/5/rzkZPXq01q5da1sle+LECfXs2dOpfhgSAgDARCxycQ6Lk/dv3LjR7vOiRYtUvXp17dq1S7fffrvOnj2rBQsWaOnSpercubMkKSkpSQ0bNtT27dvVrl07h/qhwgIAgJm4aafb7OxsuyMvL8+h7s+ePSupaINYSdq1a5cKCgoUGxtruyc6Olq1a9fWtm3bHP5aJCwAAKCY8PBwBQcH245p06b94TNWq1WjRo3SrbfeqiZNmkiSMjMz5e3trUqVKtndGxISoszMTIfjYUgIAAATcdey5qNHj9rtw+Lj88d7gCUkJOiHH37Ql19+WfIAroCEBQAAM3HTTrdBQUFObRw3bNgwrVu3Tlu2bFGtWrVs50NDQ5Wfn68zZ87YVVmysrIUGhrqcPsMCQEAgBIzDEPDhg3TqlWr9Nlnn6lu3bp211u3bq0KFSooJSXFdm7v3r06cuSIYmJiHO6HCgsAACZiMQxZXHjrjrPPJiQkaOnSpfrnP/+pwMBA27yU4OBg+fn5KTg4WIMGDdKYMWNUpUoVBQUFafjw4YqJiXF4hZBEwgIAgLlY/3u48rwTLr2suGPHjnbnk5KSNGDAAEnSzJkz5eXlpV69eikvL09xcXGaM2eOU/2QsAAAgBJz5B3Kvr6+SkxMVGJiYon7IWEBAMBErvWQ0LVCwgIAgJm4aZWQpyFhAQDATH6zW22Jn/dALGsGAAAejwoLAAAm4q6dbj0NCQsAAGbCkBAAAEDZoMICAICJWKxFhyvPeyISFgAAzIQhIQAAgLJBhQUAADNh4zgAAODpzLo1P0NCAADA41FhAQDATEw66ZaEBQAAMzEkubI02TPzFRIWAADMhDksAAAAZYQKCwAAZmLIxTksbovErUhYAAAwE5NOumVICAAAeDwqLAAAmIlVksXF5z0QCQsAACbCKiEAAIAyQoUFAAAzMemkWxIWAADMxKQJC0NCAADA41FhAQDATExaYSFhAQDATFjWDAAAPB3LmgEAAMoIFRYAAMyEOSwAAMDjWQ3J4kLSYfXMhIUhIQAA4PFIWAAAMJNLQ0KuHE7asmWL4uPjFRYWJovFotWrV/8uJEMvvPCCatSoIT8/P8XGxmr//v1O9UHCAgCAqbiarDifsJw/f17NmzdXYmLiZa9Pnz5ds2fP1rx587Rjxw75+/srLi5Oubm5DvfBHBYAAOCSrl27qmvXrpe9ZhiGZs2apb/97W/q3r27JGnJkiUKCQnR6tWr1bdvX4f6oMICAICZuGlIKDs72+7Iy8srUTgHDx5UZmamYmNjbeeCg4PVtm1bbdu2zeF2SFgAADATq+H6ISk8PFzBwcG2Y9q0aSUKJzMzU5IUEhJidz4kJMR2zREMCQEAgGKOHj2qoKAg22cfH58yjIYKCwAA5mJYXT8kBQUF2R0lTVhCQ0MlSVlZWXbns7KybNccQcICAICZlMGy5qupW7euQkNDlZKSYjuXnZ2tHTt2KCYmxuF2GBICAMBMrCVbmmz/vHNycnJ04MAB2+eDBw8qNTVVVapUUe3atTVq1ChNmTJFkZGRqlu3rsaNG6ewsDD16NHD4T5IWAAAgEt27typTp062T6PGTNGktS/f38tWrRITz/9tM6fP6/HHntMZ86c0W233aaNGzfK19fX4T5IWAAAMJMyePlhx44dZVzlOYvFokmTJmnSpEklDouEBQAAMzHkYsLitkjcikm3AADA41FhAQDATMpgSOhaIGEBAMBMrFZJVhef9zwMCQEAAI9HhQUAADNhSAgAAHg8kyYsDAkBAACPR4UFAAAzKYOt+a8FEhYAAEzEMKwyjJKv9HHl2dJEwgIAgJkYhmtVEuawAAAAlAwVFgAAzMRwcQ6Lh1ZYSFgAADATq1WyuDAPxUPnsDAkBAAAPB4VFgAAzIQhIQAA4OkMq1WGC0NCnrqsmSEhAADg8aiwAABgJgwJAQAAj2c1JIv5EhaGhAAAgMejwgIAgJkYhiRX9mHxzAoLCQsAACZiWA0ZLgwJGSQsAACg1BlWuVZhYVkzAABAiVBhAQDARBgSAgAAns+kQ0IkLNeJSxnvxV/zyzgSoBQZBWUdAVAqLqroZ/taVC8uqsClfeMuxeppSFiuE+fOnZMkfXn/gjKOBABQUufOnVNwcHCptO3t7a3Q0FB9mfmRy22FhobK29vbDVG5j8Xw1MEq2LFarTpx4oQCAwNlsVjKOhzTy87OVnh4uI4ePaqgoKCyDgdwO37Gry3DMHTu3DmFhYXJy6v01rvk5uYqP9/1Sry3t7d8fX3dEJH7UGG5Tnh5ealWrVplHcafTlBQEP8xh6nxM37tlFZl5bd8fX09LtFwF5Y1AwAAj0fCAgAAPB4JC3AZPj4+Gj9+vHx8fMo6FKBU8DOO6w2TbgEAgMejwgIAADweCQsAAPB4JCwAAMDjkbDgutSxY0eNGjWqVPuoU6eOZs2addV7JkyYoBYtWpRqHAAAEhbAYRaLRatXry7rMGAymZmZGj58uOrVqycfHx+Fh4crPj5eKSkptnu2bt2qu+++W5UrV5avr6+aNm2q1157TYWFhZKkDz/8UOXKldPx48cv20dkZKTGjBkjqXiy37FjR1ksFlksFvn4+KhmzZqKj4/XypUrHYp/xIgRat26tXx8fK6YvC9fvlwtWrRQxYoVFRERoVdeecWhtoHfImEBgDJy6NAhtW7dWp999pleeeUVff/999q4caM6deqkhIQESdKqVavUoUMH1apVS59//rn27NmjkSNHasqUKerbt68Mw1C3bt1UtWpVLV68uFgfW7Zs0YEDBzRo0KArxjFkyBBlZGQoPT1dH374oRo1aqS+ffvqsccec+h7DBw4UPfff/9lr23YsEH9+vXT0KFD9cMPP2jOnDmaOXOm3njjDYfaBmwM4DrUoUMHY/jw4cZTTz1lVK5c2QgJCTHGjx9vu3769Glj0KBBxg033GAEBgYanTp1MlJTU23XDxw4YHTr1s2oXr264e/vb7Rp08ZITk626yMiIsKYOXOm7d9V9P5TQ5IRERFhGIZhjB8/3mjevLmxZMkSIyIiwggKCjLuv/9+Izs72zAMw1i8eLFRpUoVIzc3167t7t27Gw899JD7/2BwXenatatRs2ZNIycnp9i106dPGzk5OUbVqlWNnj17Fru+Zs0aQ5KxbNkywzAMY8yYMUZkZGSx+/r372+0bdvW9rlDhw7GyJEjr/j5koULFxqSiv29uJJLfxd+74EHHjB69+5td2727NlGrVq1DKvV6lDbgGEYBhUWXLcWL14sf39/7dixQ9OnT9ekSZOUnJwsSerTp49OnjypDRs2aNeuXWrVqpXuuOMOnTp1SpKUk5Oju+++WykpKfruu+901113KT4+XkeOHLlsX998840kKSkpSRkZGbbPkpSenq7Vq1dr3bp1WrdunTZv3qyXXnrJFkdhYaHWrFlju//kyZNav369Bg4cWCp/Lrg+nDp1Shs3blRCQoL8/f2LXa9UqZI++eQT/fLLLxo7dmyx6/Hx8YqKitJ7770nSRo0aJD279+vLVu22O7JycnRihUrrlpduZL+/furcuXKDg8NXUleXl6xd9v4+fnp2LFjOnz4sEtt48+FhAXXrWbNmmn8+PGKjIzUI488ojZt2iglJUVffvmlvv76a33wwQdq06aNIiMj9eqrr6pSpUpasWKFJKl58+b661//qiZNmigyMlKTJ0/WjTfeaJdY/Fa1atUkFf0SCQ0NtX2Wit6kvWjRIjVp0kTt27fXww8/bJt/4OfnpwcffFBJSUm2+//xj3+odu3a6tixYyn9yeB6cODAARmGoejo6Cves2/fPklSw4YNL3s9Ojradk+jRo3Url07LVy40HZ9+fLlMgxDffv2dTo+Ly8vRUVF6dChQ04/+1txcXFauXKlUlJSZLVatW/fPs2YMUOSlJGR4VLb+HMhYcF1q1mzZnafa9SooZMnT2r37t3KyclR1apVFRAQYDsOHjyo9PR0SUX/5zl27Fg1bNhQlSpVUkBAgNLS0q5YYbmaOnXqKDAwsFgclwwZMkSffPKJbULkokWLNGDAAFkslpJ8bZiE4cQm447eO3DgQK1YsULnzp2TJC1cuFB9+vSx+/l0NsZLP6ddu3a1/V1q3Lixw20MGTJEw4YN0z333CNvb2+1a9fOlkB5efErCI4rX9YBACVVoUIFu88Wi0VWq1U5OTmqUaOGNm3aVOyZSpUqSZLGjh2r5ORkvfrqq6pfv778/PzUu3dv5efnuy2OS1q2bKnmzZtryZIl6tKli3788UetX7/e6X5gLpGRkbJYLNqzZ88V74mKipIkpaWl6ZZbbil2PS0tTY0aNbJ97tu3r0aPHq3ly5fr9ttv11dffaVp06aVKL7CwkLt379fN910kyTp7bff1oULFyQV/5m/GovFopdfflkvvviiMjMzVa1aNVsFsl69eiWKDX9OJCwwnVatWikzM1Ply5dXnTp1LnvPV199pQEDBujee++VVFRx+aPSd4UKFWzLSJ01ePBgzZo1S8ePH1dsbKzCw8NL1A7Mo0qVKoqLi1NiYqJGjBhRbB7LmTNn1KVLF1WpUkUzZswolrCsWbNG+/fv1+TJk23nAgMD1adPHy1cuFDp6emKiopS+/btSxTf4sWLdfr0afXq1UuSVLNmzRK1c0m5cuVsbbz33nuKiYmxG1oF/gj1OJhObGysYmJi1KNHD33yySc6dOiQtm7dqueff147d+6UVPR/tytXrlRqaqp2796tBx980K4qcjl16tRRSkqKMjMzdfr0aadievDBB3Xs2DHNnz+fybawSUxMVGFhoW6++WZ9+OGH2r9/v9LS0jR79mzFxMTI399fb775pv75z3/qscce07/+9S8dOnRICxYs0IABA9S7d2/dd999dm0OGjRIW7du1bx58xz+Wfv111+VmZmpY8eOafv27XrmmWc0dOhQPf744+rUqdNVnz1w4IBSU1OVmZmpCxcuKDU1VampqbZq5X/+8x/NmzdPe/bsUWpqqkaOHKkPPvjgDzdlBH6PhAWmY7FY9NFHH+n222/Xo48+qqioKPXt21eHDx9WSEiIJOm1115T5cqVdcsttyg+Pl5xcXFq1arVVdudMWOGkpOTFR4erpYtWzoVU3BwsHr16qWAgAD16NGjpF8NJlOvXj19++236tSpk5588kk1adJEd955p1JSUjR37lxJUu/evfX555/ryJEjat++vRo0aKCZM2fq+eef17Jly4rNhbrtttvUoEEDZWdn65FHHnEojvnz56tGjRq68cYb1bNnT/300096//33NWfOnD98dvDgwWrZsqXefPNN7du3Ty1btlTLli114sQJ2z2LFy9WmzZtdOutt+rHH3/Upk2bdPPNNzvxJwVIFsOZmV8ASuyOO+5Q48aNNXv27LIOBQCuOyQsQCk7ffq0Nm3apN69e+unn35SgwYNyjokALjuMOkWKGUtW7bU6dOn9fLLL5OsAEAJUWEBAAAej0m3AADA45GwAAAAj0fCAgAAPB4JCwAA8HgkLAAAwOORsABw2IABA+x26u3YsaNGjRp1zePYtGmTLBaLzpw5c8V7LBaLVq9e7XCbEyZMUIsWLVyK69ChQ7JYLEpNTXWpHQDFkbAA17kBAwbIYrHIYrHI29tb9evX16RJk3Tx4sVS73vlypV2L9+7GkeSDAC4EjaOA0zgrrvuUlJSkvLy8vTRRx8pISFBFSpU0HPPPVfs3vz8fHl7e7ul3ypVqrilHQD4I1RYABPw8fFRaGioIiIi9Pjjjys2NlZr1qyR9L9hnKlTpyosLMy22+7Ro0d13333qVKlSqpSpYq6d++uQ4cO2dosLCzUmDFjVKlSJVWtWlVPP/20fr/P5O+HhPLy8vTMM88oPDxcPj4+ql+/vhYsWKBDhw7Z3vpbuXJlWSwWDRgwQJJktVo1bdo01a1bV35+fmrevLlWrFhh189HH32kqKgo+fn5qVOnTnZxOuqZZ55RVFSUKlasqHr16mncuHEqKCgodt+bb76p8PBwVaxYUffdd5/Onj1rd/3tt99Ww4YN5evrq+joaIdeEAjAdSQsgAn5+fkpPz/f9jklJUV79+5VcnKy1q1bp4KCAsXFxSkwMFBffPGFvvrqKwUEBOiuu+6yPTdjxgwtWrRICxcu1JdffqlTp05p1apVV+33kUce0XvvvafZs2crLS1Nb775pgICAhQeHq4PP/xQkrR3715lZGTo73//uyRp2rRpWrJkiebNm6cff/xRo0eP1kMPPaTNmzdLKkqsevbsqfj4eKWmpmrw4MF69tlnnf4zCQwM1KJFi/TTTz/p73//u+bPn6+ZM2fa3XPgwAEtX75ca9eu1caNG/Xdd9/piSeesF1/99139cILL2jq1KlKS0vTiy++qHHjxmnx4sVOxwPASQaA61r//v2N7t27G4ZhGFar1UhOTjZ8fHyMsWPH2q6HhIQYeXl5tmfeeecdo0GDBobVarWdy8vLM/z8/IyPP/7YMAzDqFGjhjF9+nTb9YKCAqNWrVq2vgzDMDp06GCMHDnSMAzD2Lt3ryHJSE5Ovmycn3/+uSHJOH36tO1cbm6uUbFiRWPr1q129w4aNMh44IEHDMMwjOeee85o1KiR3fVnnnmmWFu/J8lYtWrVFa+/8sorRuvWrW2fx48fb5QrV844duyY7dyGDRsMLy8vIyMjwzAMw7jxxhuNpUuX2rUzefJkIyYmxjAMwzh48KAhyfjuu++u2C+AkmEOC2AC69atU0BAgAoKCmS1WvXggw9qwoQJtutNmza1m7eye/duHThwQIGBgXbt5ObmKj09XWfPnlVGRobatm1ru1a+fHm1adOm2LDQJampqSpXrpw6dOjgcNwHDhzQr7/+qjvvvNPufH5+vlq2bClJSktLs4tDkmJiYhzu45L3339fs2fPVnp6unJycnTx4kUFBQXZ3VO7dm3VrFnTrh+r1aq9e/cqMDBQ6enpGjRokIYMGWK75+LFiwoODnY6HgDOIWEBTKBTp06aO3euvL29FRYWpvLl7f9q+/v7233OyclR69at9e677xZrq1q1aiWKwc/Pz+lncnJyJEnr16+3SxSkonk57rJt2zb169dPEydOVFxcnIKDg7Vs2TLNmDHD6Vjnz59fLIEqV66c22IFcHkkLIAJ+Pv7q379+g7f36pVK73//vuqXr16sSrDJTVq1NCOHTt0++23SyqqJOzatUutWrW67P1NmzaV1WrV5s2bFRsbW+z6pQpPYWGh7VyjRo3k4+OjI0eOXLEy07BhQ9sE4ku2b9/+x1/yN7Zu3aqIiAg9//zztnOHDx8udt+RI0d04sQJhYWF2frx8vJSgwYNFBISorCwMP3888/q16+fU/0DcB2TboE/oX79+umGG25Q9+7d9cUXX+jgwYPatGmTRowYoWPHjkmSRo4cqZdeekmrV6/Wnj179MQTT1x1D5U6deqof//+GjhwoFavXm1rc/ny5ZKkiIgIWSwWrVu3Tv/+97+Vk5OjwMBAjR07VqNHj9bixYuVnp6ub7/9Vq+//rptIuvQoUO1f/9+PfXUU9q7d6+WLl2qRYsWOfV9IyMjdeTIES1btkzp6emaPXv2ZScQ+/r6qn///tq9e7e++OILjRgxQvfdd59CQ0MlSRMnTtS0adM0e/Zs7du3T99//72SkpL02muvORUPAOeRsAB/QhUrVtSWLVtUu3Zt9ezZUw0bNtSgQYOUm5trq7g8+eSTevjhh9W/f3/FxMQoMDBQ995771XbnTt3rnr37q0nnnhC0dHRGjJkiM6fPy9JqlmzpiZOnKhnn31WISEhGjZsmCRp8uTJGjdunKZNm6aGDRvqrrvu0vr161W3bl1JRfNKPvzwQ61evVrNmzfXvHnz9OKLLzr1fbt166bRo0dr2LBhatGihbZu3apx48YVu69+/frq2bOn7r77bnXp0kXNmjWzW7Y8ePBgvf3220pKSlLTpk3VoUMHLVq0yBYrgNJjMa40gw4AAMBDUGEBAAAej4QFAAB4PBIWAADg8UhYAACAxyNhAQAAHo+EBQAAeDwSFgAA4PFIWAAAgMcjYQEAAB6PhAUAAHg8EhYAAODx/h/vS/QbaL5vkgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cfm = confusion_matrix(trues, preds)\n",
    "#ConfusionMatrixDisplay(cfm, display_labels=['healthy', 'symptomatic', 'COVID-19']).plot()\n",
    "ConfusionMatrixDisplay(cfm, display_labels=['healthy', 'COVID-19']).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a40673",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "16a9e3d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0264777",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "9f480ccb6be28d4b7a840fe3b1174df64fdfbdad14d75b02fbd7e3b419aecfda"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
